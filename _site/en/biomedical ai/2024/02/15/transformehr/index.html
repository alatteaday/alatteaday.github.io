<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!--site.title site.tagline-->
  <title>
    
      [Paper] TransformEHR: transformer-based encoder-decoder generative model to enhance prediction of disease outcomes using electronic health records (2023) &middot; Coffee chats
    
  </title>

  
  <link rel="canonical" href="https://alatteaday.github.io/en/biomedical%20ai/2024/02/15/transformehr/">
  

  <link rel="stylesheet" href="https://alatteaday.github.io/en/public/css/poole.css">
  <link rel="stylesheet" href="https://alatteaday.github.io/en/public/css/syntax.css">
  <link rel="stylesheet" href="https://alatteaday.github.io/en/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://alatteaday.github.io/en/public/favicon.ico/apple-touch-icon.png">
  <link rel="shortcut icon" href="https://alatteaday.github.io/en/public/favicon.ico/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="RSS" href="https://alatteaday.github.io/en/atom.xml">

  
</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>Curation of studies, techs, ideas and her journey as a maching learning engineer</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="https://alatteaday.github.io/en/">Home</a>

    

    
    
      
        
        
      
    
      
        
        
      
    
      
        
          <a class="sidebar-nav-item" 
          href="https://alatteaday.github.io/en/about/">About</a>
        
        
      
    
      
    
      
        
        
          <a class="sidebar-nav-item "
          href="https://alatteaday.github.io/en/category/CV/">Computer Vision</a>
        
      
    
      
        
        
          <a class="sidebar-nav-item "
          href="https://alatteaday.github.io/en/category/NLP/">Natural Language Processing</a>
        
      
    
      
        
        
          <a class="sidebar-nav-item "
          href="https://alatteaday.github.io/en/category/bio/">Biomedical AI</a>
        
      
    
      
        
        
          <a class="sidebar-nav-item "
          href="https://alatteaday.github.io/en/category/error/">Error Resolution</a>
        
      
    
      
    
      
        
          <a class="sidebar-nav-item" 
          href="https://alatteaday.github.io/en/tags/">Tags</a>
        
        
      
    
    <!--
    <a class="sidebar-nav-item" href="/en/archive/v1.1.0.zip">Download</a>
    <a class="sidebar-nav-item" href="">GitHub project</a>
    <span class="sidebar-nav-item">Currently v1.1.0</span> 
    -->
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2024. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <!--site.title site.tagline-->
    <div class="wrap">
      <div class="masthead">
        <div class="container" >
          <h3 class="masthead-title">
            <a href="/en/" title="Home">Coffee chats</a>
            <small>with strangers</small>
          </h3>
          <div class="lang-switcher">
    
    
eng
    

    
    
        
<a href=" /biomedical%20ai/2024/02/15/transformehr/">kor</a>
        
    

</div>
        </div>
      </div>

      <div class="container content">
        <div class="post">
  <h1 class="post-title">[Paper] TransformEHR: transformer-based encoder-decoder generative model to enhance prediction of disease outcomes using electronic health records (2023)</h1>
  <p class="post-date">15 Feb 2024&nbsp;&nbsp;&nbsp;&nbsp;
    <!--<span class="post-date">15 Feb 2024</span>-->
    
      
        
          <span class="tag">
            <a href=".">
              #bio
            </a>
          </span>
        
      
        
          <span class="tag">
            <a href=".">
              #ehr
            </a>
          </span>
        
      
        
          <span class="tag">
            <a href=".">
              #transformer
            </a>
          </span>
        
      
    
  </p>
  <p>Yang, Zhichao, et al. “TransformEHR: transformer-based encoder-decoder generative model to enhance prediction of disease outcomes using electronic health records.” <em>Nature Communications</em> 14.1 (2023): 7857.</p>

<p><a href="https://www.nature.com/articles/s41467-023-43715-z">paper link</a></p>

<h2 id="points">Points</h2>

<ol>
  <li>
    <p>New pre-training objective: predicting all diseases or outcomes of a future visit</p>

    <ul>
      <li>helps the model uncover the complex interrelations among different diseases and outcomes</li>
    </ul>
  </li>
  <li>
    <p><strong>TransformEHR</strong>, the generative encoder-decoder framework to predict patients’ ICD codes using their longitudinal EHRs</p>
  </li>
  <li>
    <p>Validation of the generalizability using both internal and external datasets</p>

    <ul>
      <li>
        <p>demonstrated a strong transfer learning capability of the model</p>
      </li>
      <li>
        <p>could be great with limited data and computing resources</p>
      </li>
    </ul>
  </li>
</ol>

<h2 id="background">Background</h2>

<ul>
  <li>Longitudinal electronic health records (EHRs) have been successfully used to predict clinical diseases or outcomes (congestive heart failure, sepsis mortality, mechanical ventilation, septic shock, diabetes, PTSD, etc.)</li>
  <li>With the availability of large cohorts and computational resources, deep learning (DL) based models outperform traditional machine learning (ML) models (Med-BERT, BEHRT, BRLTM, etc.)</li>
  <li>The existing pre-training tasks were limited in predicting a fraction of ICD codes within each visit :arrow_right: A novel pre-training strategy, which predicts the complete set of diseases and outcomes within a visit, might improve clinical predictive modeling</li>
</ul>

<h2 id="method">Method</h2>

<h3 id="data">Data</h3>

<p>*VHA: Veterans Health Administration, the largest integrated healthcare system in the US, providing care at 1,321 healthcare facilities</p>

<p>Pre-training data: around 6M patients who received care from more than 1,200 facilities of the US VHA</p>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/_images/2024-02-15-transformehr/table1.png?raw=true" style="zoom: 67%;" /></p>

<ul>
  <li>
    <p>Two common and uncommon disease/outcome agnostic prediction (DOAP) datasets</p>

    <ul>
      <li>ICD-10CM codes with more than a 2% prevalence ratio for common dataset</li>
      <li>Those with a 0.04%-0.05% prevalence ratio for uncommon dataset</li>
    </ul>
  </li>
  <li>
    <p>Non-VHA dataset: from MIMIC-IV dataset (29,482)</p>

    <ul>
      <li>Only selected objects with ICD-10CM records to match the cohorts from VHA</li>
    </ul>
  </li>
</ul>

<h3 id="longitudinal-ehrs">Longitudinal EHRs</h3>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/_images/2024-02-15-transformehr/fig1.png?raw=true" alt="image-20240306100731535" style="zoom:67%;" /></p>

<ul>
  <li>
    <p>Include demographic information (gender, age, race, and marital status) and ICD-10CM codes as predictors</p>
  </li>
  <li>
    <p>Group ICD codes at the visit level</p>
  </li>
  <li>
    <p>Order the codes by priority, where the primary diagnosis is typically given the highest priority</p>
  </li>
  <li>
    <p>Form multiple visits as a time-stamped input of a sequence by date of visit</p>
  </li>
</ul>

<h3 id="embeddings">Embeddings</h3>

<p><img src="file:///Users/jiyun/Documents/Gitlog/alatteaday.github.io/_images/2024-02-15-transformehr/KakaoTalk_Image_2024-03-13-09-14-52_007.png" alt="KakaoTalk_Image_2024-03-13-09-14-52_007" /><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/_images/2024-02-15-transformehr/fig2.png?raw=true" alt="image-20240306103928325" /></p>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/_images/2024-02-15-transformehr/code_embeds1.png?raw=true" alt="image-20240306110913978" /></p>

<p>Multi-level embeddings: visit embeddings + time embeddings + code embeddings</p>

<ul>
  <li>Time embeddings: embed days difference as relative time information by getting the difference between a certain visit and the last visit in the EHR
    <ul>
      <li>Includes the date of each visit to integrate temporal information, not only sequential order</li>
      <li>Date is important as the importance of predictor in a visit can vary over time</li>
    </ul>
  </li>
</ul>

<h3 id="model-architecture">Model Architecture</h3>

<p>Encoder-decoder transformer-based architecture</p>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/_images/2024-02-15-transformehr/fig3.png?raw=true" alt="image-20240306114845710" style="zoom:80%;" /></p>

<ul>
  <li>Encoder: performs cross-attention, unlikely BERT, over representations and assigns an attention weight for each representation
    <ul>
      <li>Cross-attention is implemented by masking the complete set of ICD codes of a future visit as shown in Fig. 2b</li>
    </ul>
  </li>
  <li>Decoder: generates ICD codes of the masked future visit with the weighted representations from the encoder
    <ul>
      <li>Generates the codes following the order of code priority within a visit</li>
    </ul>
  </li>
</ul>

<h2 id="evaluation">Evaluation</h2>

<p>Metrics: PPV (precision), AUROC, AUPRC</p>

<p>Baseline models: logistic regression, LSTM, BERT without pre-training, BERT with pre-training    <span style="color:silver;"> # what’s the objective when pre-training BERT? MLM or the objective proposed in this paper? </span></p>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/_images/2024-02-15-transformehr/table2_3_4.png?raw=true" alt="image-20240306175748572" /></p>

<h4 id="pre-training">Pre-training</h4>

<p>Task: Disease or outcome agnostic prediction (DOAP); Predicting the ICD codes of a patient’s future visit based on longitudinal information up to the current visit</p>

<p><strong>Ablation study</strong></p>

<ol>
  <li>
    <p>Visit masking vs. code (part of visit) masking for an encoder-decoder model</p>

    <p>:arrow_right: visit masking performed better; pre-training of all diseases outperform traditional pre-training objective (2.52-2.96% in AUROC)</p>
  </li>
  <li>
    <p>Encoder-decoder vs. encoder-only (BERT) on DOAP</p>

    <p>:arrow_right: ​encoder-decoder outperformed; 0.74-1.16% in AUROC      # the possibility if the parameter size affected this result?</p>
  </li>
  <li>
    <p>Time embeddings O vs. X</p>

    <p>:arrow_right: the model with the time embeddings outperformed moderately; 0.43 in AUROC</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>* days difference is more effective than specific date as the embeddings 
</code></pre></div>    </div>
  </li>
</ol>

<h4 id="fine-tuning">Fine-tuning</h4>

<p>Tasks: the pancreatic cancer onset prediction (Table 3) and intentional self-harm prediction in patients with PTSD (Table 4)</p>

<ul>
  <li>TransformEHR outperforms on the both tasks</li>
  <li>
    <p>AUPRC was consistent when using different set of demographics</p>
  </li>
  <li>Results with all visits was better than with recent few(five) visits</li>
  <li>In generalizability evaluation,
    <ul>
      <li>when testing with internal dataset which is included data from VHA facilities not used for pre-training, there’s no statistical difference in AUPRC on the intentional self-harm prediction task among PTSD</li>
    </ul>
  </li>
</ul>

</div>


<div class="related">
  <h2 class="related-title">Related posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="/en/error%20resolution/2024/02/20/dockercmd/">
            Docker CMDs&nbsp;
            <small>20 Feb 2024</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/en/biomedical%20ai/2024/01/31/WMHandAbTau/">
            [Study] Relations between white matter hyperintensity (WMH) feature and amyloid-beta (β-amyloid) and tau burden&nbsp;
            <small>31 Jan 2024</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/en/biomedical%20ai/2024/01/22/BEHRT/">
            [Paper] BEHRT: Transformer for Electronic Health Records (2020)&nbsp;
            <small>22 Jan 2024</small>
          </a>
        </h3>
      </li>
    
  </ul>
</div>


      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script src='/public/js/script.js'></script>
  </body>
</html>
