<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!--site.title site.tagline-->
  <title>
    
      Coffee Chat &middot; Brewing AI Knowledge
    
  </title>

  
  <link rel="canonical" href="https://alatteaday.github.io/page4/">
  

  <link rel="stylesheet" href="https://alatteaday.github.io/public/css/poole.css">
  <link rel="stylesheet" href="https://alatteaday.github.io/public/css/syntax.css">
  <link rel="stylesheet" href="https://alatteaday.github.io/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://alatteaday.github.io/public/favicon.ico/apple-touch-icon.png">
  <link rel="shortcut icon" href="https://alatteaday.github.io/public/favicon.ico/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="RSS" href="https://alatteaday.github.io/atom.xml">

  
</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>Curation of studies, techs, ideas and a journey as a maching learning engineer</p>
  </div>

  <nav class="sidebar-nav">

    <a class="sidebar-nav-item" href="https://alatteaday.github.io/about">About</a>
    <a class="sidebar-nav-item active" href="https://alatteaday.github.io/">Home</a>
    <a class="sidebar-nav-item" href="https://alatteaday.github.io/tags">Tags</a>

    

    
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
          <a class="sidebar-nav-item" 
          href="https://alatteaday.github.io/about/">About</a>
        
        -->
        
      
    
      
    
      
        <!--
        
        -->
        
          <a class="sidebar-nav-item "
          href="https://alatteaday.github.io/category/error/">Dev Tips & Fixes</a>
        
      
    
      
        <!--
        
        -->
        
          <a class="sidebar-nav-item "
          href="https://alatteaday.github.io/category/papers/">Papers</a>
        
      
    
      
        <!--
        
        -->
        
          <a class="sidebar-nav-item "
          href="https://alatteaday.github.io/category/study/">Study</a>
        
      
    
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
    <!--
    <a class="sidebar-nav-item" href="/archive/v1.1.0.zip">Download</a>
    <a class="sidebar-nav-item" href="">GitHub project</a>
    <span class="sidebar-nav-item">Currently v1.1.0</span> 
    -->
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2024. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <!--site.title site.tagline-->
    <div class="wrap">
      <div class="masthead">
        <div class="container" >
          <h3 class="masthead-title">
            <a href="/" title="Home">Coffee Chat</a>
            <small>Brewing AI Knowledge</small>
          </h3>
          <div class="lang-switcher">
    
    
        eng
    

    
    
        
            <a href="/ko/page4/">kor</a>
        
    

</div>
        </div>
      </div>

      <div class="container content">
        <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="https://alatteaday.github.io/study/2023/12/26/mri2/">
        [LearnMRI] The Types of MRI Modalities and Observable Brain Patterns
      </a>
    </h1>
    <!--<span class="post-date">26 Dec 2023</span>-->
    <p class="post-date">26 Dec 2023&nbsp;&nbsp;&nbsp;&nbsp;
      
        
          
            <span class="tag" data-tag="bio">
              <a href="https://alatteaday.github.io/tags/?tag=bio">
                #bio
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="brainImaging">
              <a href="https://alatteaday.github.io/tags/?tag=brainImaging">
                #brainImaging
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="mri">
              <a href="https://alatteaday.github.io/tags/?tag=mri">
                #mri
              </a>
            </span>
            
        
      
    </p>
    <!--
    
    -->
    <p>According to the <a href="https://alatteaday.github.io/study/2023/12/26/mri/">Spin echo</a> technique, T1-weighted images (T1WI) and T2-weighted images (T2WI) can be obtained. By manipulating these images, various MR modality images can be created. Since the signal intensity of lesion tissue varies in each image, the types of lesions emphasized are different.</p>

<p align="center">
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-12-25-mri/t1_t2_flair.png?raw=true" style="zoom: 50%;" />
</p>

<p><br /></p>

<h2 id="t1-weighted-image-t1wi">T1-weighted Image (T1WI)</h2>

<ul>
  <li>Spin echo: Both the repetition time (TR) and the echo time (TE) are set short.
    <ul>
      <li>When TR is shortened, the recovery time (T1 realxation time) of $Mz$ varies depending on the tissue, emphasizing the difference. Some tissues have fully recovered, while others have not fully recovered by the time of the second pulse, leading to varying influences from the second pulse. This difference is reflected in the image.</li>
      <li>TE should be set short to minimize its influence on the T2 relaxation time values.</li>
    </ul>
  </li>
  <li>Signal intensity
    <ul>
      <li>Signal intensity is higher than T2 → anatomical structures are more clearly distinguished.</li>
      <li>Subcutaneous fat and blood appear hyperintense, which means brighter, while muscles appear intermediate, and water appears hypointense, which means darker.</li>
      <li>Marrow, being rich in fat, appears hyperintense, while cortex, having less water, appears hypointense.</li>
      <li>Lesions: Lipoma, acute hemorrhage, lesions containing high protein content (e.g., mucocele)</li>
    </ul>
  </li>
  <li>Observation: Cortical morphology (anatomical detail), vascular changes, blood-brain barrier integrity</li>
  <li>Feature: Cortical thickness, <a href="https://alatteaday.github.io/study/2023/12/26/mri3/">choroid plexus (ChP)</a></li>
  <li><br /></li>
</ul>

<h2 id="t2-weighted-image-t2wi">T2-weighted image (T2WI)</h2>

<ul>
  <li>Spin echo: Both TR and TE are set long.
    <ul>
      <li>Lengthening TR minimizes its impact on T1 relaxation time.</li>
      <li>Longer TE emphasizes the contrast in the extent of $Mxy$ decrease, resulting in different tissue representations in the image.</li>
    </ul>
  </li>
  <li>Signal intensity:
    <ul>
      <li>Water appears hyperintense, aiding in the detection of pathological tissues with higher water content, such as lesions.</li>
      <li>Most lesions appear as low signal intensity(hypointense) on T1 and high signal intensity(hyperintense) on T2.</li>
      <li>The brightness of water in T2 images varies, with cysts appearing brightest, followed by edema, and then normal tissue.</li>
      <li>Muscles, fat, and blood appear hypointense.</li>
      <li>Cerebrospinal fluid (CSF) also appears hyperintense, making it challenging to distinguish lesions, such as Perivascular space (PVS).</li>
    </ul>
  </li>
  <li>Observation: Lesions, hypointense lesions (such as acute hematomas, fungal balls, etc.), arteries (veins show varying signal intensities due to differing blood flow rates)</li>
  <li>Feature: <a href="https://alatteaday.github.io/study/2023/12/26/mri3/">Perivascular space (PVS)</a></li>
</ul>

<p><br /></p>

<h2 id="flair-fluid-attenuation-inversion-recovery">FLAIR (Fluid Attenuation Inversion Recovery)</h2>

<ul>
  <li>CSF is rendered black in T2 images.</li>
  <li>Non-free-flowing water appears hyperintense, while fat appears hypointense.</li>
  <li>Observation: Lesions around the ventricles, edema (which appears bright due to stanant fluid), grey-white matter differentiation.</li>
  <li>Feature: Lesions, <a href="https://alatteaday.github.io/study/2023/12/26/mri3/">white matter hyperintensity (WMH)</a></li>
</ul>

<p><br /></p>

<h2 id="gre-gradient-echo-t2">GRE (Gradient Echo; T2*)</h2>

<p align="center">
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-12-25-mri/gre.png?raw=true" style="zoom: 25%;" />
</p>

<ul>
  <li>Paramagnetic substances such as blood, calcium, and metal appear hyperintense, allowing for the observation of iron deposition.</li>
  <li>Observation: Excellent for detecting microbleeds in early and late brain hemorrhages, as well as diffuse axonal injury.
    <ul>
      <li>*Diffuse axonal injury: One of the components of brain trauma, characterized by axonal damage leadidng to a coma state after trauma.</li>
    </ul>
  </li>
  <li>Feature: bleeding</li>
</ul>


    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$$', '$$$'], ['\\[', '\\]'] ],
        processEscapes: true,
      }
    });
    MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="https://alatteaday.github.io/study/2023/12/26/mri/">
        [LearnMRI] Principles and Characteristics of MRI imaging
      </a>
    </h1>
    <!--<span class="post-date">26 Dec 2023</span>-->
    <p class="post-date">26 Dec 2023&nbsp;&nbsp;&nbsp;&nbsp;
      
        
          
            <span class="tag" data-tag="bio">
              <a href="https://alatteaday.github.io/tags/?tag=bio">
                #bio
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="brainImaging">
              <a href="https://alatteaday.github.io/tags/?tag=brainImaging">
                #brainImaging
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="mri">
              <a href="https://alatteaday.github.io/tags/?tag=mri">
                #mri
              </a>
            </span>
            
        
      
    </p>
    <!--
    
    -->
    <p>I’d like to write posts summarizing various aspects of MRI and its modalities, as well as the Alzheimer’s disease-related features observable through MRI as I studied.</p>

<h2 id="magnetic-resonance-imaging-mri">Magnetic Resonance Imaging (MRI)</h2>

<p>In a device composed of magnets, high-frequency waves are directed at the human body, resonating hydrogen atomic nuclei in the body’s tissues, and converting the differences in signals emanating from each tissue into digital information, resulting in images.</p>

<p><br /></p>

<h2 id="principles-of-mri-imaging">Principles of MRI Imaging</h2>

<p>Human tissues contain a significant amount of water. Hydrogen nuclei within water molecules possess magnetic properties. By emitting high-frequency waves, these hydrogen nuclei can be resonated. When a radiofrequency (RF) pulse is emitted and then turned off (RF pulse), the atomic nuclei absorb and subsequently release the high-frequency signal. Analyzing the differences in the signals returning to the MRI device and maximizing them, a two-dimensional image is formed, which is the essence of MRI.</p>

<p>The magnitude and waveform of the emitted signal vary depending on factors such as the concentration of water molecules, blood flow, and the binding state with surrounding chemical structures. Consequently, the relaxation times, T1 and T2, differ based on the composition of tissues and blood. Since the composition varies with different diseases, the signals obtained also differ accordingly. By capturing these signal variations, various types of MRI images can be obtained, including <a href="https://alatteaday.github.io/study/2023/12/26/mri2/">T1-weighted images (T1WI), T2-weighted images (T2WI), FLAIR, and others</a>.</p>

<p align="center">
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-12-25-mri/mr_axis.png?raw=true" style="zoom: 40%;" align="center" />
</p>

<p>The T1 and T2 relaxation times are measured based on different criteria after applying a 90-degree RF pulse to the protons. When the magnetization of the protons is flipped from the longitudinal axis ($Mz$) to the transverse axis, an $Mxy$ vector is formed. The T1 and T2 relaxation times are measured from the moment when the $Mz$ vector reaches 0% and the $Mxy$ vector reaches 100%.</p>

<ul>
  <li>T1 relaxation time: The time it takes for $Mz$ to recover up to 63%.
    <ul>
      <li>Recovery is faster in fat, brain tissue, and cerebrospinal fluid (CSF) in that order (shorter T1 relaxation time).</li>
    </ul>
  </li>
  <li>T2 relaxation time: The time it takes for $Mxy$ to decay down to 37%, relatively unaffected by magnetic field strength.
    <ul>
      <li>Signal decay is faster in fat, brain tissue, and CSF.</li>
      <li>Tissues with shorter T1 relaxation times also exhibit a rapid decline in the T2 curve.
Water and fat have opposite signal intensities in T1 and T2 (opposite signal intensity).</li>
    </ul>
  </li>
</ul>

<p>Spin echo is a technique for acquiring images by manipulating the repetition time (TR) and echo time (TE) while applying RF pulses of 90 and 180 degrees. TR is the time from one 90-degree pulse to the next, while TE is the time until the signal is obtained after the 90-degree pulse. By repeating the pulse during image acquisition, various images can be obtained by adjusting TR and TE.</p>

<p><br /></p>

<h2 id="pros-and-cons-of-mri">Pros and Cons of MRI</h2>

<p>Pros</p>
<ul>
  <li>Better contrast of soft tissues compared to CT.</li>
  <li>Ability to observe anatomical, physiological, and functional information.</li>
</ul>

<p>Cons</p>
<ul>
  <li>Ferromagnetic artifacts: Even small amounts of ferromagnetic materials in the body can disrupt the homogeneity of the magnetic field, causing distortion in the images.</li>
  <li>Presence of dental fillings or other inserted materials can reduce image quality.</li>
</ul>

<p>Contraindications</p>
<ul>
  <li>MRI should not be used for patients with implants or other materials inside the body that may be affected by the magnetic field.</li>
</ul>


    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$$', '$$$'], ['\\[', '\\]'] ],
        processEscapes: true,
      }
    });
    MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="https://alatteaday.github.io/papers/2023/11/05/rag/">
        [Paper] Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (NIPS 2020)
      </a>
    </h1>
    <!--<span class="post-date">05 Nov 2023</span>-->
    <p class="post-date">05 Nov 2023&nbsp;&nbsp;&nbsp;&nbsp;
      
        
          
            <span class="tag" data-tag="llm">
              <a href="https://alatteaday.github.io/tags/?tag=llm">
                #llm
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="transformer">
              <a href="https://alatteaday.github.io/tags/?tag=transformer">
                #transformer
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="nlp">
              <a href="https://alatteaday.github.io/tags/?tag=nlp">
                #nlp
              </a>
            </span>
            
        
      
    </p>
    <!--
    
    -->
    <p>Lewis, Patrick, et al. “Retrieval-augmented generation for knowledge-intensive nlp tasks.” <em>Advances in Neural Information Processing Systems</em> 33 (2020): 9459-9474.</p>

<p><a href="https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html">Paper Link</a></p>

<h1 id="points">Points</h1>

<ul>
  <li><strong>Retrieval Augmented Generation (RAG)</strong> model combines a retriever and a generator for enhanced knowledge-intense tasks.</li>
  <li>RAG Variants: RAG-Sequence uses a single document for output; RAG-Token integrates multiple documents per token.</li>
  <li>RAG models outperform baselines in open-domain QA, abstractive QA, Jeopardy question generation, and fact verification.</li>
  <li>RAG models demonstrate practical benefits with easy updates to the non-parametric memory.</li>
</ul>

<p><br /></p>

<h1 id="background">Background</h1>

<ul>
  <li>Large pre-trained Language models (LLMs) store factual knowledge in their parameters, functioning as implicit knowledge base.</li>
  <li>LLMs, however, have limitations: they cannot expand their memory, provide insight into their predictions, and may produce ‘hallucinations’.</li>
  <li>Recently, hybrid models, such as REALM and ORQA, address these issues by using a differentiable retriever to revised and expanded knowledge, showing promising results, primarily in open-domain question answering (QA).</li>
</ul>

<p><br /></p>

<h1 id="method">Method</h1>

<p align="center">
    <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-11-05-rag/fig1.png?raw=true" style="zoom: 100%;" />
</p>

<p>Retrieval-augmented generation (RAG) fine-tunes pre-trained generation models with a non-parametric memory for a general-purpose tasks.</p>
<ul>
  <li>Parametric memory: a pre-trained seq2seq transformer</li>
  <li>Non-parametric memory: a dense vector index of Wikipedia, accessed with a pre-trained neural retriever.</li>
  <li>Dense passage retriever (DPR): retrieves latent documents conditioned on the input.</li>
  <li>BART: the generator conditions on the latent documents together with the input to generate the output. Other seq2seq models like T5 can also be used and fine-tuned with the retriever.</li>
  <li>Latent documents: marginalized using a top-K approximation, either on a per-output basis or a per-token basis.
    <ul>
      <li>RAG-Sequence Model: assumes the same document is responsible for all tokens.</li>
      <li>RAG-Token Model: considers different documents for different tokens.</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="models">Models</h2>

<p>RAG models use the input sequence $x$ to retrieve text documents $z$ and use them as additional context when generating the target sequence $y$. RAG has two components:</p>
<ul>
  <li>Retriever $p_\eta(z\mid x)$: returns distributions over text passages given a query $x$ with parameters $\eta$.
    <ul>
      <li>Truncated as top-K assumtion.</li>
    </ul>
  </li>
  <li>Generator $p_\theta(y_i\mid x,z,y_{1:i-1})$: generates a current token based on the previous $i-1$ tokens $y_{1:i-1}$, the input $x$, and a retrieved passage $z$ with parameters $\theta$.</li>
</ul>

<p>The retriever and the generator are trained end-to-end, treating the retrieved document as a latent variable. To marginalize over the latent documents, two methods are proposed, RAG-Sequence and RAG-Token.</p>

<p><br /></p>

<h2 id="rag-sequence-and-rag-token">RAG-Sequence and RAG-Token</h2>

<p><strong>RAG-Sequence Model</strong> uses the same retrieved document to generate the complete sequence.</p>
<ul>
  <li>The retrieved document is a single latent variable to get the seq2seq probability $p(y\mid x)$ via a top-K approximation.</li>
  <li>The top-K documents are retrieved using the retriever, and generator produces the output sequence probability for each document.</li>
</ul>

\[p_{RAG-Sequence}(y\mid x) \approx \sum_{z\in top-k(p(\cdot|x))}{p_\eta(z|x)p_\theta(y_i|x,z)} \\ = \sum_{z\in top-k(p(\cdot|x))}{p_\eta(z|x)}\prod_i^N p_\theta(y_i|x,z,y_{1:i-1})\]

<ul>
  <li>Use cases: Better suited for tasks where the context of entire documents is crucial, like summarization tasks.</li>
</ul>

<p><strong>RAG-Token Model</strong> uses different latent documents for each target token.</p>
<ul>
  <li>The generator chooses content from several documents for the answer.</li>
  <li>The top-K documents are retrieved using the retriever, and the generator produces a distribution for the next output token for each document before marginalizing.</li>
</ul>

\[p_{RAG-Token}(y|x)\approx \prod_i^N \sum_{z\in top-k(p(\cdot\mid x))}p_\eta(z\mid x)p_\theta(y_i\mid x,z_i,y_{1:i-1})\]

<ul>
  <li>Use cases: More suitable for tasks that benefit from integrating detailed information from multiple sources, like open-domain QA.</li>
</ul>

<p><br /></p>

<h2 id="retriever-and-generator">Retriever and Generator</h2>

<p><strong>Retriever</strong> $p_\mu(z\mid x)$ is based on DPR, which follows a bi-encoder architecture:</p>

\[p_\mu(z|x)\propto \exp(\bf d \rm (z)^\top \bf q \rm (x)) \\
\bf d \rm (z)=\rm BERT_d(z), \ \bf q \rm (x)=\rm BERT_q(x)\]

<ul>
  <li>$\bf d \rm (z)$: a dense representation of a document produced by a document encoder based on $\rm BERT_{BASE}$.</li>
  <li>$\bf q \rm (x)$: a query representation produced by a query encoder based on $\rm BERT_{BASE}$.</li>
  <li><span style="background-color:#fff5b1">Maximum inner product search (MIPS)</span>: caculates top-k $p_\eta(\cdot\mid x)$ approximately in sub-linear time.</li>
  <li><span style="background-color:#fff5b1">Non-parametric memory</span>: the index of the document. The retriever is trained to retrieve documents containing answers to TriviaQA questions and Natural Questions.</li>
</ul>

<p><strong>Generator</strong> $p_\theta(y_i\mid x,z,y_{1:i-1})$ can be any encoder-decoder model, based on BART in the paper.</p>
<ul>
  <li>$\rm BART_{large}$ is used: a pre-trained seq2seq transformer with 400M parameters, pre-trained using a denoising objective with various noising functions.</li>
  <li>The input $x$ and the retrieved document $z$ are concatenated and then inputted into $\rm BART$ model to generate the output.</li>
  <li><span style="background-color:#fff5b1">Parametric memory</span>: $\rm BART$ generator parameters $\theta$.</li>
</ul>

<p><br /></p>

<h2 id="training">Training</h2>

<p>The retriever and generator are trained jointly without direct supervision on which document should be retrieved.</p>
<ul>
  <li>Objective: Minimize the negative marginal log-likelihood of each target with a corpus of input/output pairs $(x_j, y_j)$, $\sum_j-\log(p(y_j\mid x_j))$.
    <ul>
      <li>Adam optimizer.</li>
    </ul>
  </li>
  <li>Fine-tuning only the query encoder $\rm BERT_q$ and the generator $\rm BART$ during training.
    <ul>
      <li>Updating the document encoder $\rm BERT_d$ is costly and ineffective
        <ul>
          <li>Requires periodic updating of the document index (as REALM).</li>
          <li>Not necessary for strong performance.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="decoding">Decoding</h2>

<p>For testing, RAG-Sequence and RAG-Token require different methos to approximate $\arg \max_y{p(y\mid x)}$.</p>

<p><strong>RAG-Sequence model</strong> utilizes beam search for each document $z$. It can’t be solved with a single beam search, as the likelihood $p(y\mid x)$ does not break into a conventional per-token likelihood.</p>
<ul>
  <li>Each hypothesis of $z$ is scored by $p_\theta(y_i\mid x,z,y_{1:i-1})$.</li>
  <li>Some hypothesis $y$ included in the set of hypothesis $Y$ may not have appeared in the beams of all documents.</li>
  <li><span style="background-color:#fff5b1">Thorough Decoding</span>: To estimate the probability of $y$, (1) Run an additional forward pass for each $z$ where $y$ doesn’t appear in the beam, (2) multiply the generator probability with $p_\eta(z\mid x)$, and (3) sum the probabilities across beams.</li>
  <li><span style="background-color:#fff5b1">Fast Decoding</span>: For efficient decoding, Approximate $p_\theta(y\mid x,z_i) \approx 0$ where $y$ wasn’t generated during beam search from $x, z_i$, avoiding additional forward passes once the candidate set $Y$ is generated.</li>
  <li>For longer output sequences, $\left\vert Y \right\vert$ can be large with many forward passes.</li>
</ul>

<p><strong>RAG-Token model</strong> is a basic autoregressive seq2seq generator with transition probability:</p>

\[p'_\theta(y_i\mid x,y_{1,i-1})=\sum_{z\in top-k(p(\cdot \mid x))}p_\eta(z_i \mid x)p_\theta(y_i\mid x,z_i,y_{1:i-1})\]

<p><br /></p>

<h1 id="experiments">Experiments</h1>

<p>The experiments were conducted on several datasets to evaluate the model’s performance in knowledge-intensive NLP tasks.</p>
<ul>
  <li>Wikipedia December 2018 dump was used as the non-parametric knowledge source.</li>
  <li>Wikipedia articles were split into 100-word chunks, totaling 21M documents.</li>
  <li>An embedding for each document was calculated by the document encoder $\rm BERT_d$, and a single MIPS index was built with Hierarchical Navigable Small World approximation for fast retrieval.</li>
  <li>When retrieving the top $k$ documents for each query, $k\in {5,10}$ was considered for training, and set using dev data for test time.</li>
</ul>

<h2 id="tasks">Tasks</h2>

<ol>
  <li><strong>Open-domain Question Answering (QA)</strong>: an important real-world application and common testbed for knowledge-intensive tasks.
    <ul>
      <li>Text pairs $(x,y)$ are matched as questions and answers.</li>
      <li>RAG is trained to minimize the negative log-likelihood of answers.</li>
      <li>Close-book QA is also a compared task: generating answers without retrieving but purely with parametric knowledge.</li>
      <li>Datasets: Natural Questions, TriviaQA, WebQuestions, CuratedTREC</li>
    </ul>
  </li>
  <li><strong>Abstractrive Question Answering</strong>: tests natural language generation (NLG) ability with free-form and abstractive cases.
    <ul>
      <li>Use MSMARCO NLG Task v2.1: only the question and answers, not existing gold passages in the dataset, treated as an open-domain abstractive QA task.</li>
    </ul>
  </li>
  <li><strong>Jeopardy Question Generation</strong>: evaluates the generation ability in a non-QA setting.
    <ul>
      <li>Jeopardy: guessing an entity from a fact about that entity.
        <ul>
          <li>e.g., “In 1986 Mexico scored as the first contry to host this international sport competition twice.” where the answer is “The World Cup”.</li>
        </ul>
      </li>
      <li>Jeopardy questions are precise and factual, making it a challenging, knowledge-intensive task to generate them conditioned on the anser entities.</li>
    </ul>
  </li>
  <li><strong>Fact Verification</strong> (FEVER): a retrieval problem coupled with an challenging entailment reasoning task.
    <ul>
      <li>Requires classifying whether a text is supported or refuted by Wikipedia or whether there’s not enough information to decide.</li>
      <li>Provides an appropriate testved for exploring a model’s ability to handle classification rather than generation.</li>
      <li>Two varients: the 3-way classification (supports/refutes/not enough) and the 2-way (support/refutes).</li>
    </ul>
  </li>
</ol>

<p><br /></p>

<h1 id="results">Results</h1>

<p>The results demonstrated that both RAG-Sequence and RAG-Token models outperformed baseline models across various datasets and tasks.</p>

<h2 id="open-domain-qa">Open-Domain QA</h2>

<p align="center">
    <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-11-05-rag/table1_2.png?raw=true" style="zoom: 100%;" />
</p>

<ul>
  <li>RAG models significantly outperformed the baselines, showing higher EM and F1 scores.</li>
  <li>The RAG-Token model, in particular, performed well due to its ability to integrate detailed information from multiple documents.</li>
</ul>

<p><br /></p>

<h2 id="abstractive-question-answering">Abstractive Question Answering</h2>

<p align="center">
    <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-11-05-rag/table3.png?raw=true" style="zoom: 100%;" />
</p>

<ul>
  <li>RAG models achieved SOTA performance, even though many questions are unanswerable without the gold passages.</li>
  <li>RAG models hallucinated less and generated more factually correct and diverse text compared to BART (Table 3).</li>
</ul>

<p><br /></p>

<h2 id="jeopardy-question-generation">Jeopardy Question Generation</h2>

<p align="center">
    <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-11-05-rag/table4_5.png?raw=true" style="zoom: 100%;" />
</p>
<p>
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-11-05-rag/fig2.png?raw=true" style="zoom: 100%;" />
</p>

<ul>
  <li>Both of RAG models outperformed BART on Q-BLEU-1 (Table 2).</li>
  <li>Human evaluators indicate that RAG-generated content was more factual in 42.7% of cases, demostrating the effectiveness of RAG over the SOTA generation model (Table 4).</li>
  <li>RAG-Token model performed better than RAG-Sequence, combining content from several documents effectively (Fig 2).</li>
  <li>The generator’s the parametric knowledge sufficed to complete the generation after initially referencing the document (Fig 2).</li>
</ul>

<p><br /></p>

<h2 id="fact-verification">Fact Verification</h2>

<ul>
  <li>For 3-way classification, RAG achieved scores within 4.3% of SOTA models trained with intermediate retrieval supervision for a specific domain.</li>
  <li>For 2-way classification, RAG achieved performance within 2.7% of the base model, SotA, which were trained to classify true of false given the gold evidences.</li>
  <li>The documents retrieved by RAG are overlapped significantly with FEVER’s gold evidence.</li>
</ul>

<p><br /></p>

<h2 id="additional-results">Additional Results</h2>

<ol>
  <li>
    <p><strong>Generation Diversity</strong>: When investigating generation diversity by calculating the ratio of distinct ngrams to total ngrams generated by different models, RAG models generated more diverse outputs compared to BART. RAG-Sequence produced slightly more diverse outputs than RAG-Token (Table 5).</p>
  </li>
  <li><strong>Retrieval Ablations</strong>: Freezing the retriever during training resulted in lower performance compared to the original RAG models. Replacing the retriever with a BM25 system showed that learned retrieval improved performance for all task (table 6).
    <p align="center">
    <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-11-05-rag/table6.png?raw=true" style="zoom: 100%;" />
</p>
  </li>
  <li>
    <p><strong>Index hot-swapping</strong>: Demonstrated the advantage of non-parametric memory by using an index from Wikipedia dump from December 2016. RAG models still answered 70% of questions correctly, showing that knowledge can be updated simply by replacing the non-parametric memory.</p>
  </li>
  <li><strong>Effect of Retrieving more documents</strong>: Adjusting the number of retrieved documents at test time showed improved performance up to a certain point, demonstrating the benefits of retrieveing more relevant documents (fig 3).
    <p align="center">
    <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-11-05-rag/table6.png?raw=true" style="zoom: 100%;" />
</p>
  </li>
</ol>

<p><br /></p>

    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$$', '$$$'], ['\\[', '\\]'] ],
        processEscapes: true,
      }
    });
    MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="https://alatteaday.github.io/papers/2023/09/15/STraTS/">
        [Paper] Self-Supervised Transformer for Sparse and Irregularly Sampled Multivariate Clinical Time-Series (ACM 2022)
      </a>
    </h1>
    <!--<span class="post-date">15 Sep 2023</span>-->
    <p class="post-date">15 Sep 2023&nbsp;&nbsp;&nbsp;&nbsp;
      
        
          
            <span class="tag" data-tag="bio">
              <a href="https://alatteaday.github.io/tags/?tag=bio">
                #bio
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="ehr">
              <a href="https://alatteaday.github.io/tags/?tag=ehr">
                #ehr
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="transformer">
              <a href="https://alatteaday.github.io/tags/?tag=transformer">
                #transformer
              </a>
            </span>
            
        
      
    </p>
    <!--
    
    -->
    <p>Tipirneni, Sindhu, and Chandan K. Reddy. “Self-supervised transformer for sparse and irregularly sampled multivariate clinical time-series.” <em>ACM Transactions on Knowledge Discovery from Data (TKDD)</em> 16.6 (2022): 1-17.</p>

<p><a href="https://dl.acm.org/doi/full/10.1145/3516367">Paper Link</a></p>

<h2 id="points">Points</h2>

<p><strong>Self-supervised Transformer for Time-Series (STraTS) model</strong></p>

<ul>
  <li>
    <p>Using observation triplets as time-series components: avoids the problems faced by aggregation and imputation methods for sparse and sporadic multivariate time-series</p>
  </li>
  <li>
    <p>Continuous Value Embedding: encodes continuous time and variable values without the need for discretization</p>
  </li>
  <li>
    <p>Transformer-based model: learns contextual triplet embeddings</p>
  </li>
  <li>
    <p>Time series forecasting as a proxy task: leverages unlabeled data to learn better generalized representations</p>
  </li>
</ul>

<h2 id="background">Background</h2>

<p>Problems</p>

<ul>
  <li>Multivariate time-series data are frequently observed in critical care settings and are typically characterized by sparsity (missing information) and irregular time intervals.</li>
  <li>Existing approaches, such as aggregation or imputation of values, suppress the fine-grained information and add undesirable noise/overhead into the model.</li>
  <li>The problem of limited availability of labeled data is easily observed in healthcare applications.</li>
</ul>

<p>The clinical domain portrays a unique set of challenges:</p>

<ul>
  <li>Missingness and Sparsity: Not all the variables are observed for every patient. Also, the time-series matrices are very sparse.</li>
  <li>Irregular time intervals and Sporadicity: Not all clinical variables are measured at regular time intervals. The measurements may occur sporadically in time depending.</li>
  <li>Limited labeled data: expensive and even more limited for specific tasks.</li>
</ul>

<p>Existing methods</p>

<ul>
  <li>Aggregation: could suppress important fine-grained information</li>
  <li>Imputation/Interpolation: not reasonable as not considering the domain knowledge about each variable</li>
</ul>

<h2 id="method">Method</h2>

<p><strong>Self-supervised Transformer for Time-Series (STraTS)</strong></p>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-09-15-strats/1_fig3.png?raw=true" alt="" /></p>

<h3 id="embeddings">Embeddings</h3>

<p><strong>Triplet Emgeddings</strong> = Feature embedding + Value embedding + Time embedding
\(T=\{(t_i, j_i, u_i)\}^n_{i=1}\\
e_i=e_i^f+e_i^v+e_i^t\)
<strong>Continuous Value Embedding (CVE)</strong></p>

<p>For continuous values of feature values and times</p>

<p>A one-to-many Feed-Forward Network
\(FFN(x) = U tanh(Wx+b)\)</p>

<ul>
  <li>
    <p>Feature embeddings $e_i^f$: obtained from a simpole lookup table</p>
  </li>
  <li>
    <p>Value embeddings $e_i^v$ and Time embeddings$e_i^t$: through CVE</p>
  </li>
</ul>

<p><strong>Demographics Embedding</strong></p>

<p>the prediction models performed better when demographics were processed separately.
\(e^𝑑 = 𝑡𝑎𝑛ℎ(W^𝑑_2𝑡𝑎𝑛ℎ(W^𝑑_1d + b^𝑑_1) + b^𝑑_2) ∈ R^d\)
where the hidden layer has a dimension of 2d</p>

<h3 id="self-supervision">Self-Supervision</h3>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-09-15-strats/2_fig2.png?raw=true" alt="" /></p>

<p>Pre-training Tasks: Both masking and forecasting as pretext tasks for providing self-supervision</p>

<p>The forecasitng improved the results on target tasks</p>

<p>The loss is:
\(L_{ss}=\frac{1}{|N'|}\sum_{k=1}^{N'}\sum_{j=1}^{|F|}m_j^k\Big(\tilde{z}_j^k-z_j^k\Big)^2\)</p>

<h3 id="interpretability">Interpretability</h3>

<p>I-STraTS: an interpretable version of STraTS</p>

<ul>
  <li>The output can be expressed using a linear combination of components that are derived from individual features</li>
</ul>

<p>Differences with STraTS</p>

<ul>
  <li>Combine the initial triplet embeddings in Fusion Self-attention module</li>
  <li>Directly use the raw demographics vector as the demographics embedding</li>
</ul>

\[\tilde{y}=sigmoid\Big(\sum_{j=1}^{D}{\bold{w}_0[j]d[j]+\sum_{i=1}^{n}\sum_{j=1}^{d}\alpha_i\bold{w}_o[j+D]\bold{e}_i[j]+b_o}\Big)\]

<h2 id="experiments">Experiments</h2>

<p>Target Task: Prediction of in-hospital mortality</p>

<p>Datasets: 2 EHR datasets; MIMIC-III and PhysioNet Challenge 2012</p>

<ul>
  <li>MIMIC-III: 46,000 patients</li>
  <li>PhysioNet-2012: 11,988 patients</li>
</ul>

<p>Baselines: Gated Recurrent Unit (GRU), Temporal Convolutional Network (TCN), Simply Attend and DIagnose (SaND), GRU with trainable Decays (GRU-D), Interpolation-prediction Network (InterpNet), Set Functions for Time Series (SeFT)</p>

<ul>
  <li>Used 2 dense layers for demographics encoding</li>
  <li>Concatenated it to the time-series representation before the last dense layer</li>
</ul>

<p>Metrics</p>

<ul>
  <li>ROC-AUC: Area under ROC curve</li>
  <li>PR-AUC: Area under precision-recall curve</li>
  <li>min(Re, Pr): the max of ‘min of recall and precision’ across all thresholds</li>
</ul>

<h3 id="prediction-performance">Prediction Performance</h3>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-09-15-strats/3_table4.png?raw=true" style="zoom:80%;" /></p>

<ul>
  <li>Trained each model using 10 different random samplings of 50% labeled data from the train and validation sets</li>
  <li>STraTS uses the entire labeled data and additional unlabeled data if avaliable</li>
  <li>STraTS achieves the best performance</li>
  <li>GRU showed better performance than interpolation-based models (GRU-D, InterpNet) on the MIMIC-III dataset, which was not expected</li>
</ul>

<p><strong>Generalizability test of models</strong></p>

<p>Lower propotions of labeled data can be observed in real-world when there are several right-censord samples.</p>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-09-15-strats/4_fig5.png?raw=true" alt="" /></p>

<ul>
  <li>STraTS has an advantage compared to others in scarce labeled data settings, which can be attributed to self-supervision</li>
</ul>

<h3 id="ablation-study">Ablation Study</h3>

<p>Compared STraTS and I-STraTS with and without self-supervision: ‘ss+’ and ‘ss-‘ indicate each case</p>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-09-15-strats/5_table5.png?raw=true" style="zoom:80%;" /></p>

<ul>
  <li>I-STraTS showed slightly worse performance as constrained its representations</li>
  <li>Adding self-supervision improves performance of both models</li>
  <li>I-STraTS(ss+) outperforms STraTS(ss-): self-supervision can compensate the performance which could get lower by introducing interpretability</li>
</ul>

<h3 id="interpretability-1">Interpretability</h3>

<p>How I-STraTS explains its predictions</p>

<p>A case study: a 85 yrs old female patient from MIMIC-III</p>

<ul>
  <li>expired on the 6th day after ICU admission</li>
  <li>had 380 measurements corresponding to 58 time-series variables</li>
</ul>

<p>The model predicts the probability of her in-hospital mortality as 0.94 using only the data collected the first day</p>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-09-15-strats/6_table6.png?raw=true" alt="" /></p>

<ul>
  <li>Average contribution score: the average score along with the range, for multiple observations, or value, for only one observation</li>
  <li>The top 5 variables are the most important factors in predicting she ‘s at high risk of mortality that the model observed</li>
</ul>

<p>&amp;rarr Can be helpful to identify high-risk patients and also understand the contributing factors and make better diagnoses, especially at the early stages of treatment</p>

    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$$', '$$$'], ['\\[', '\\]'] ],
        processEscapes: true,
      }
    });
    MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="https://alatteaday.github.io/study/2023/08/29/demensiapapers/">
        [Study] 알츠하이머 치매의 ATN 바이오마커 간 관계 정리
      </a>
    </h1>
    <!--<span class="post-date">29 Aug 2023</span>-->
    <p class="post-date">29 Aug 2023&nbsp;&nbsp;&nbsp;&nbsp;
      
        
          
            <span class="tag" data-tag="bio">
              <a href="https://alatteaday.github.io/tags/?tag=bio">
                #bio
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="brainImaging">
              <a href="https://alatteaday.github.io/tags/?tag=brainImaging">
                #brainImaging
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="demensia">
              <a href="https://alatteaday.github.io/tags/?tag=demensia">
                #demensia
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="atn">
              <a href="https://alatteaday.github.io/tags/?tag=atn">
                #atn
              </a>
            </span>
            
        
      
    </p>
    <!--
    
      Docker image 및 container와 관련하여 자주 사용되는 명령어를 정리해봅니다.
    
    -->
    <h2 id="ai-전공자의-알츠하이머-치매-관련-brain-imaging-논문-스터디">AI 전공자의 알츠하이머 치매 관련 Brain Imaging 논문 스터디</h2>

<p>Amyloid Beta(A), Tau(T), Neurodegeneration(N)과 관련된 Alzheimer’s Disease(AD) 기전에 대해 이해하기 위하여 다음의 논문들을 읽고 정리한 내용입니다. 기반 지식이 없어 시각 자료와 사전을 찾아가며 읽었습니다. pdf는 찾아본 이미지와 필기한 내용이 담긴 논문 파일입니다.</p>

<p>Ittner, Lars M., and Jürgen Götz. “Amyloid-β and tau—a toxic pas de deux in Alzheimer’s disease.” <em>Nature Reviews Neuroscience</em> 12.2 (2011): 67-72. <a href="https://www.nature.com/articles/nrn2967">link</a> <a href="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-08-29-demensiapapers/nrn2967.pdf">pdf</a></p>

<p>Vogel, Jacob W., et al. “Four distinct trajectories of tau deposition identified in Alzheimer’s disease.” <em>Nature medicine</em> 27.5 (2021): 871-881. <a href="https://www.nature.com/articles/s41591-021-01309-6">link</a> <a href="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-08-29-demensiapapers/s41591-021-01309-6.pdf">pdf</a></p>

<p>Lee, Wha Jin, et al. “Regional Aβ-tau interactions promote onset and acceleration of Alzheimer’s disease tau spreading.” <em>Neuron</em>110.12 (2022): 1932-1943. <a href="https://pubmed.ncbi.nlm.nih.gov/35443153/">link</a> <a href="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-08-29-demensiapapers/regional_onset.pdf">pdf</a></p>

<hr />

<p>Amyloid Beta(A)는 뉴런에 의해 생성되는 Amyloid Precursor Protein(APP)이 프로테아제에 의해 4부분으로 나눠질 때 생기는 펩타이드 중 하나로,</p>

<p>뉴런 근처에 존재하여 기능 장애를 야기하는 것으로 알려졌다. A의 침착은 Alzheimer’s Disease(AD) 발병 10-20년 전부터 이뤄진다.</p>

<ul>
  <li>
    <p>A는 dimers, oligomers, fibrils 등에 이어 plaque를 형성한다. A가 어느 형태에서 toxicity를 갖기 시작하는지는 확실하지 않다. 항 아밀로이드 치매 치료제는 이 plaque의 감소와 증식 및 생성 방지를 목적으로 한다.</p>
  </li>
  <li>
    <p>A의 toxicity는 postsynaptic compartment, 즉 dendrite(somatodendritic region)를 주 대상으로 하여 작용하고, 특정 수용체의 속성에 따라 세포막을 통해 간접적으로 뉴런에 영향을 끼칠 수 있다. 대표적인 특정 수용체로 NMDAR이 있다.</p>
  </li>
</ul>

<p>Tau(T)는 신경 세포에서 microtubule과 결합하는 단백질로, 주로 axon에 존재하여 microtubule의 안정화 및 axonal transition을 조절하는 역할을 한다.</p>

<p>정상 상태의 뉴런의 dendrite에도 소량 존재한다.</p>

<p>T는 A에 의해 과인산화되고(hyperphosphorylated Tau), 과인산화된 T는 Neurofibrillary Tangle(NFT)를 형성한다.</p>

<ul>
  <li>T의 과인산화는 microtubule 형성을 방해하여 뉴런의 기능을 방해한다.</li>
  <li>NFT는 Somatodendritic region에서 많이 관찰된다. T의 level이 높아지면 T가 dendrite에서 많이 관찰된다.</li>
</ul>

<p>Dendrite에서 T는 그곳에 위치한 여러 단백질과 상호작용하여 결과적으로 뉴런이 A의 toxicity에 약해지게 만든다.</p>

<ul>
  <li>T가 인산화되면 Tyrosine protein kinasen FYN과 강하게 작용한다. 과인산화된 T가 dendrite에서 증가함에 따라 FYN도 Soma에서 증가한다.</li>
  <li>FYN은 NMDAR을 인산화한다. 인산화된 NMDAR은 Postsynaptic Density Protein 95(PDS95)와 상호작용한다.</li>
  <li>이것의 결과로 NMDAR의 excitotoxicity가 나타난다(흥분독성상태). 수용체의 excitotoxicity로 A의 toxicity에 뉴런이 민감해지게 된다.</li>
</ul>

<p>결과적으로 A와 T는 뉴런을 약화시키는 데에 있어 서로 시너지를 갖는다. A는 T의 과인산화를 촉진하고, 과인산화된 T는 뉴런이 A의 toxicity에 약해지게 만든다.</p>

<p>이 시스템에서 A와 T는 세포의 다른 부분(각각 Complex I, Complex IV)에 악영향을 끼쳐 미토콘드리아 호흡을 방해하고, 결국 Neurodegeneration(N)을 야기한다.</p>

<p>따라서 A의 침착과 T의 전파는 AD의 중요한 요인이다.</p>

<p>T의 전파 양상은 Braak Staging System으로 체계화된 바 있다.</p>

<ul>
  <li>Transentorhinal cortex → medial and basal temporal lobe → neocortical associative regions → unimodal sensory and motor cortex</li>
</ul>

<p>그런데 이 system에 부합하지 않는 전파 양상 또한 관찰되었다. T의 전파 양상을 병의 진행과 뇌 영역의 시공간적 기준으로 분류하여 4가지 subtype으로 정의할 수 있다.</p>

<ul>
  <li>S1 limbic (Braak system), S2 MTL, S3 posterior, S4 Lateral Temporal</li>
</ul>

<p>침착된 A는 T의 전파에 영향을 준다.</p>

<ul>
  <li>A는 heteromodal association cortex에 침착되고, T의 전파는 entorhinal cortex(EC)에서 시작되어 점차 뇌 전반으로 퍼진다. ( ← Braak system; S1 type ? )</li>
  <li>Remote Interation: A와 T가 같은 영역에 있지 않은 상태에서, 먼저 A가 연결된 뉴런을 통해서 EC 영역에 있는 T에 영향을 준다. A의 영향으로 T는 점차 주위 영역으로 확산된다.</li>
  <li>Local Interaction: T가 A와 직접적으로 접촉되어 있는 뉴런에 전파되어 만남으로서 T의 전파가 가속화된다(acceleration). 해당 뇌 영역은 Internal Temporal Gyrus(ITG)이다 (propagation hub).</li>
  <li>T 전파의 acceleration이 진행되면 뇌 전반에서 A와 T의 상호작용이 일어나게 되어 N과 AD의 악화를 막기 어렵다.</li>
</ul>

<p>A와 T의 PET 데이터와 MRI 데이터를 병의 진행에 따라 살펴보면</p>

<ul>
  <li>A의 침착되는 정도는 뇌 전반에 걸쳐 점점 심해질 것이고</li>
  <li>T는 뇌의 특정 부분에서 시작하여 점차 확산되는 양상으로 관찰되고</li>
  <li>T의 슈퍼 전파가 관찰된 이후 MRI 상 전반적인 뇌 위축(N)의 정도가 심하게 나타날 것이다.</li>
</ul>


    
  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="https://alatteaday.github.io/page5">Older</a>
  
  
    
      <a class="pagination-item newer" href="https://alatteaday.github.io/page3">Newer</a>
    
  
</div>

        
      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script src='/public/js/script.js'></script>
  </body>
</html>
