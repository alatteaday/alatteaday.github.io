<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!--site.title site.tagline-->
  <title>
    
      Coffee Chat &middot; Brewing AI Knowledge
    
  </title>

  
  <link rel="canonical" href="https://alatteaday.github.io/page4/">
  

  <link rel="stylesheet" href="https://alatteaday.github.io/public/css/poole.css">
  <link rel="stylesheet" href="https://alatteaday.github.io/public/css/syntax.css">
  <link rel="stylesheet" href="https://alatteaday.github.io/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://alatteaday.github.io/public/favicon.ico/apple-touch-icon.png">
  <link rel="shortcut icon" href="https://alatteaday.github.io/public/favicon.ico/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="RSS" href="https://alatteaday.github.io/atom.xml">

  
</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>Curation of studies, techs, ideas and a journey as a maching learning engineer</p>
  </div>

  <nav class="sidebar-nav">

    <a class="sidebar-nav-item" href="https://alatteaday.github.io/about">About</a>
    <a class="sidebar-nav-item active" href="https://alatteaday.github.io/">Home</a>
    <a class="sidebar-nav-item" href="https://alatteaday.github.io/tags">Tags</a>

    

    
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
          <a class="sidebar-nav-item" 
          href="https://alatteaday.github.io/about/">About</a>
        
        -->
        
      
    
      
    
      
        <!--
        
        -->
        
          <a class="sidebar-nav-item "
          href="https://alatteaday.github.io/category/error/">Dev Tips & Fixes</a>
        
      
    
      
        <!--
        
        -->
        
          <a class="sidebar-nav-item "
          href="https://alatteaday.github.io/category/papers/">Papers</a>
        
      
    
      
        <!--
        
        -->
        
          <a class="sidebar-nav-item "
          href="https://alatteaday.github.io/category/study/">Study</a>
        
      
    
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
    <!--
    <a class="sidebar-nav-item" href="/archive/v1.1.0.zip">Download</a>
    <a class="sidebar-nav-item" href="">GitHub project</a>
    <span class="sidebar-nav-item">Currently v1.1.0</span> 
    -->
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2024. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <!--site.title site.tagline-->
    <div class="wrap">
      <div class="masthead">
        <div class="container" >
          <h3 class="masthead-title">
            <a href="/" title="Home">Coffee Chat</a>
            <small>Brewing AI Knowledge</small>
          </h3>
          <div class="lang-switcher">
    
    
        eng
    

    
    
        
            <a href="/ko/page4/">kor</a>
        
    

</div>
        </div>
      </div>

      <div class="container content">
        <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="https://alatteaday.github.io/study/2023/12/26/mri2/">
        [LearnMRI] The Types of MRI Modalities and Observable Brain Patterns
      </a>
    </h1>
    <!--<span class="post-date">26 Dec 2023</span>-->
    <p class="post-date">26 Dec 2023&nbsp;&nbsp;&nbsp;&nbsp;
      
        
          
            <span class="tag" data-tag="bio">
              <a href="https://alatteaday.github.io/tags/?tag=bio">
                #bio
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="brainImaging">
              <a href="https://alatteaday.github.io/tags/?tag=brainImaging">
                #brainImaging
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="mri">
              <a href="https://alatteaday.github.io/tags/?tag=mri">
                #mri
              </a>
            </span>
            
        
      
    </p>
    <!--
    
    -->
    <p>According to the <a href="https://alatteaday.github.io/study/2023/12/26/mri/">Spin echo</a> technique, T1-weighted images (T1WI) and T2-weighted images (T2WI) can be obtained. By manipulating these images, various MR modality images can be created. Since the signal intensity of lesion tissue varies in each image, the types of lesions emphasized are different.</p>

<p align="center">
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-12-25-mri/t1_t2_flair.png?raw=true" style="zoom: 50%;" />
</p>

<p><br /></p>

<h2 id="t1-weighted-image-t1wi">T1-weighted Image (T1WI)</h2>

<ul>
  <li>Spin echo: Both the repetition time (TR) and the echo time (TE) are set short.
    <ul>
      <li>When TR is shortened, the recovery time (T1 realxation time) of $Mz$ varies depending on the tissue, emphasizing the difference. Some tissues have fully recovered, while others have not fully recovered by the time of the second pulse, leading to varying influences from the second pulse. This difference is reflected in the image.</li>
      <li>TE should be set short to minimize its influence on the T2 relaxation time values.</li>
    </ul>
  </li>
  <li>Signal intensity
    <ul>
      <li>Signal intensity is higher than T2 â†’ anatomical structures are more clearly distinguished.</li>
      <li>Subcutaneous fat and blood appear hyperintense, which means brighter, while muscles appear intermediate, and water appears hypointense, which means darker.</li>
      <li>Marrow, being rich in fat, appears hyperintense, while cortex, having less water, appears hypointense.</li>
      <li>Lesions: Lipoma, acute hemorrhage, lesions containing high protein content (e.g., mucocele)</li>
    </ul>
  </li>
  <li>Observation: Cortical morphology (anatomical detail), vascular changes, blood-brain barrier integrity</li>
  <li>Feature: Cortical thickness, <a href="https://alatteaday.github.io/study/2023/12/26/mri3/">choroid plexus (ChP)</a></li>
  <li><br /></li>
</ul>

<h2 id="t2-weighted-image-t2wi">T2-weighted image (T2WI)</h2>

<ul>
  <li>Spin echo: Both TR and TE are set long.
    <ul>
      <li>Lengthening TR minimizes its impact on T1 relaxation time.</li>
      <li>Longer TE emphasizes the contrast in the extent of $Mxy$ decrease, resulting in different tissue representations in the image.</li>
    </ul>
  </li>
  <li>Signal intensity:
    <ul>
      <li>Water appears hyperintense, aiding in the detection of pathological tissues with higher water content, such as lesions.</li>
      <li>Most lesions appear as low signal intensity(hypointense) on T1 and high signal intensity(hyperintense) on T2.</li>
      <li>The brightness of water in T2 images varies, with cysts appearing brightest, followed by edema, and then normal tissue.</li>
      <li>Muscles, fat, and blood appear hypointense.</li>
      <li>Cerebrospinal fluid (CSF) also appears hyperintense, making it challenging to distinguish lesions, such as Perivascular space (PVS).</li>
    </ul>
  </li>
  <li>Observation: Lesions, hypointense lesions (such as acute hematomas, fungal balls, etc.), arteries (veins show varying signal intensities due to differing blood flow rates)</li>
  <li>Feature: <a href="https://alatteaday.github.io/study/2023/12/26/mri3/">Perivascular space (PVS)</a></li>
</ul>

<p><br /></p>

<h2 id="flair-fluid-attenuation-inversion-recovery">FLAIR (Fluid Attenuation Inversion Recovery)</h2>

<ul>
  <li>CSF is rendered black in T2 images.</li>
  <li>Non-free-flowing water appears hyperintense, while fat appears hypointense.</li>
  <li>Observation: Lesions around the ventricles, edema (which appears bright due to stanant fluid), grey-white matter differentiation.</li>
  <li>Feature: Lesions, <a href="https://alatteaday.github.io/study/2023/12/26/mri3/">white matter hyperintensity (WMH)</a></li>
</ul>

<p><br /></p>

<h2 id="gre-gradient-echo-t2">GRE (Gradient Echo; T2*)</h2>

<p align="center">
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-12-25-mri/gre.png?raw=true" style="zoom: 25%;" />
</p>

<ul>
  <li>Paramagnetic substances such as blood, calcium, and metal appear hyperintense, allowing for the observation of iron deposition.</li>
  <li>Observation: Excellent for detecting microbleeds in early and late brain hemorrhages, as well as diffuse axonal injury.
    <ul>
      <li>*Diffuse axonal injury: One of the components of brain trauma, characterized by axonal damage leadidng to a coma state after trauma.</li>
    </ul>
  </li>
  <li>Feature: bleeding</li>
</ul>


    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$$', '$$$'], ['\\[', '\\]'] ],
        processEscapes: true,
      }
    });
    MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="https://alatteaday.github.io/study/2023/12/26/mri/">
        [LearnMRI] Principles and Characteristics of MRI imaging
      </a>
    </h1>
    <!--<span class="post-date">26 Dec 2023</span>-->
    <p class="post-date">26 Dec 2023&nbsp;&nbsp;&nbsp;&nbsp;
      
        
          
            <span class="tag" data-tag="bio">
              <a href="https://alatteaday.github.io/tags/?tag=bio">
                #bio
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="brainImaging">
              <a href="https://alatteaday.github.io/tags/?tag=brainImaging">
                #brainImaging
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="mri">
              <a href="https://alatteaday.github.io/tags/?tag=mri">
                #mri
              </a>
            </span>
            
        
      
    </p>
    <!--
    
    -->
    <p>Iâ€™d like to write posts summarizing various aspects of MRI and its modalities, as well as the Alzheimerâ€™s disease-related features observable through MRI as I studied.</p>

<h2 id="magnetic-resonance-imaging-mri">Magnetic Resonance Imaging (MRI)</h2>

<p>In a device composed of magnets, high-frequency waves are directed at the human body, resonating hydrogen atomic nuclei in the bodyâ€™s tissues, and converting the differences in signals emanating from each tissue into digital information, resulting in images.</p>

<p><br /></p>

<h2 id="principles-of-mri-imaging">Principles of MRI Imaging</h2>

<p>Human tissues contain a significant amount of water. Hydrogen nuclei within water molecules possess magnetic properties. By emitting high-frequency waves, these hydrogen nuclei can be resonated. When a radiofrequency (RF) pulse is emitted and then turned off (RF pulse), the atomic nuclei absorb and subsequently release the high-frequency signal. Analyzing the differences in the signals returning to the MRI device and maximizing them, a two-dimensional image is formed, which is the essence of MRI.</p>

<p>The magnitude and waveform of the emitted signal vary depending on factors such as the concentration of water molecules, blood flow, and the binding state with surrounding chemical structures. Consequently, the relaxation times, T1 and T2, differ based on the composition of tissues and blood. Since the composition varies with different diseases, the signals obtained also differ accordingly. By capturing these signal variations, various types of MRI images can be obtained, including <a href="https://alatteaday.github.io/study/2023/12/26/mri2/">T1-weighted images (T1WI), T2-weighted images (T2WI), FLAIR, and others</a>.</p>

<p align="center">
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-12-25-mri/mr_axis.png?raw=true" style="zoom: 40%;" align="center" />
</p>

<p>The T1 and T2 relaxation times are measured based on different criteria after applying a 90-degree RF pulse to the protons. When the magnetization of the protons is flipped from the longitudinal axis ($Mz$) to the transverse axis, an $Mxy$ vector is formed. The T1 and T2 relaxation times are measured from the moment when the $Mz$ vector reaches 0% and the $Mxy$ vector reaches 100%.</p>

<ul>
  <li>T1 relaxation time: The time it takes for $Mz$ to recover up to 63%.
    <ul>
      <li>Recovery is faster in fat, brain tissue, and cerebrospinal fluid (CSF) in that order (shorter T1 relaxation time).</li>
    </ul>
  </li>
  <li>T2 relaxation time: The time it takes for $Mxy$ to decay down to 37%, relatively unaffected by magnetic field strength.
    <ul>
      <li>Signal decay is faster in fat, brain tissue, and CSF.</li>
      <li>Tissues with shorter T1 relaxation times also exhibit a rapid decline in the T2 curve.
Water and fat have opposite signal intensities in T1 and T2 (opposite signal intensity).</li>
    </ul>
  </li>
</ul>

<p>Spin echo is a technique for acquiring images by manipulating the repetition time (TR) and echo time (TE) while applying RF pulses of 90 and 180 degrees. TR is the time from one 90-degree pulse to the next, while TE is the time until the signal is obtained after the 90-degree pulse. By repeating the pulse during image acquisition, various images can be obtained by adjusting TR and TE.</p>

<p><br /></p>

<h2 id="pros-and-cons-of-mri">Pros and Cons of MRI</h2>

<p>Pros</p>
<ul>
  <li>Better contrast of soft tissues compared to CT.</li>
  <li>Ability to observe anatomical, physiological, and functional information.</li>
</ul>

<p>Cons</p>
<ul>
  <li>Ferromagnetic artifacts: Even small amounts of ferromagnetic materials in the body can disrupt the homogeneity of the magnetic field, causing distortion in the images.</li>
  <li>Presence of dental fillings or other inserted materials can reduce image quality.</li>
</ul>

<p>Contraindications</p>
<ul>
  <li>MRI should not be used for patients with implants or other materials inside the body that may be affected by the magnetic field.</li>
</ul>


    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$$', '$$$'], ['\\[', '\\]'] ],
        processEscapes: true,
      }
    });
    MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="https://alatteaday.github.io/papers/2023/11/05/rag/">
        [Paper] Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (NIPS 2020)
      </a>
    </h1>
    <!--<span class="post-date">05 Nov 2023</span>-->
    <p class="post-date">05 Nov 2023&nbsp;&nbsp;&nbsp;&nbsp;
      
        
          
            <span class="tag" data-tag="llm">
              <a href="https://alatteaday.github.io/tags/?tag=llm">
                #llm
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="transformer">
              <a href="https://alatteaday.github.io/tags/?tag=transformer">
                #transformer
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="nlp">
              <a href="https://alatteaday.github.io/tags/?tag=nlp">
                #nlp
              </a>
            </span>
            
        
      
    </p>
    <!--
    
    -->
    <p>Lewis, Patrick, et al. â€œRetrieval-augmented generation for knowledge-intensive nlp tasks.â€ <em>Advances in Neural Information Processing Systems</em> 33 (2020): 9459-9474.</p>

<p><a href="https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html">Paper Link</a></p>

<h1 id="points">Points</h1>

<ul>
  <li><strong>Retrieval Augmented Generation (RAG)</strong> model combines a retriever and a generator for enhanced knowledge-intense tasks.</li>
  <li>RAG Variants: RAG-Sequence uses a single document for output; RAG-Token integrates multiple documents per token.</li>
  <li>RAG models outperform baselines in open-domain QA, abstractive QA, Jeopardy question generation, and fact verification.</li>
  <li>RAG models demonstrate practical benefits with easy updates to the non-parametric memory.</li>
</ul>

<p><br /></p>

<h1 id="background">Background</h1>

<ul>
  <li>Large pre-trained Language models (LLMs) store factual knowledge in their parameters, functioning as implicit knowledge base.</li>
  <li>LLMs, however, have limitations: they cannot expand their memory, provide insight into their predictions, and may produce â€˜hallucinationsâ€™.</li>
  <li>Recently, hybrid models, such as REALM and ORQA, address these issues by using a differentiable retriever to revised and expanded knowledge, showing promising results, primarily in open-domain question answering (QA).</li>
</ul>

<p><br /></p>

<h1 id="method">Method</h1>

<p align="center">
    <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-11-05-rag/fig1.png?raw=true" style="zoom: 100%;" />
</p>

<p>Retrieval-augmented generation (RAG) fine-tunes pre-trained generation models with a non-parametric memory for a general-purpose tasks.</p>
<ul>
  <li>Parametric memory: a pre-trained seq2seq transformer</li>
  <li>Non-parametric memory: a dense vector index of Wikipedia, accessed with a pre-trained neural retriever.</li>
  <li>Dense passage retriever (DPR): retrieves latent documents conditioned on the input.</li>
  <li>BART: the generator conditions on the latent documents together with the input to generate the output. Other seq2seq models like T5 can also be used and fine-tuned with the retriever.</li>
  <li>Latent documents: marginalized using a top-K approximation, either on a per-output basis or a per-token basis.
    <ul>
      <li>RAG-Sequence Model: assumes the same document is responsible for all tokens.</li>
      <li>RAG-Token Model: considers different documents for different tokens.</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="models">Models</h2>

<p>RAG models use the input sequence $x$ to retrieve text documents $z$ and use them as additional context when generating the target sequence $y$. RAG has two components:</p>
<ul>
  <li>Retriever $p_\eta(z\mid x)$: returns distributions over text passages given a query $x$ with parameters $\eta$.
    <ul>
      <li>Truncated as top-K assumtion.</li>
    </ul>
  </li>
  <li>Generator $p_\theta(y_i\mid x,z,y_{1:i-1})$: generates a current token based on the previous $i-1$ tokens $y_{1:i-1}$, the input $x$, and a retrieved passage $z$ with parameters $\theta$.</li>
</ul>

<p>The retriever and the generator are trained end-to-end, treating the retrieved document as a latent variable. To marginalize over the latent documents, two methods are proposed, RAG-Sequence and RAG-Token.</p>

<p><br /></p>

<h2 id="rag-sequence-and-rag-token">RAG-Sequence and RAG-Token</h2>

<p><strong>RAG-Sequence Model</strong> uses the same retrieved document to generate the complete sequence.</p>
<ul>
  <li>The retrieved document is a single latent variable to get the seq2seq probability $p(y\mid x)$ via a top-K approximation.</li>
  <li>The top-K documents are retrieved using the retriever, and generator produces the output sequence probability for each document.</li>
</ul>

\[p_{RAG-Sequence}(y\mid x) \approx \sum_{z\in top-k(p(\cdot|x))}{p_\eta(z|x)p_\theta(y_i|x,z)} \\ = \sum_{z\in top-k(p(\cdot|x))}{p_\eta(z|x)}\prod_i^N p_\theta(y_i|x,z,y_{1:i-1})\]

<ul>
  <li>Use cases: Better suited for tasks where the context of entire documents is crucial, like summarization tasks.</li>
</ul>

<p><strong>RAG-Token Model</strong> uses different latent documents for each target token.</p>
<ul>
  <li>The generator chooses content from several documents for the answer.</li>
  <li>The top-K documents are retrieved using the retriever, and the generator produces a distribution for the next output token for each document before marginalizing.</li>
</ul>

\[p_{RAG-Token}(y|x)\approx \prod_i^N \sum_{z\in top-k(p(\cdot\mid x))}p_\eta(z\mid x)p_\theta(y_i\mid x,z_i,y_{1:i-1})\]

<ul>
  <li>Use cases: More suitable for tasks that benefit from integrating detailed information from multiple sources, like open-domain QA.</li>
</ul>

<p><br /></p>

<h2 id="retriever-and-generator">Retriever and Generator</h2>

<p><strong>Retriever</strong> $p_\mu(z\mid x)$ is based on DPR, which follows a bi-encoder architecture:</p>

\[p_\mu(z|x)\propto \exp(\bf d \rm (z)^\top \bf q \rm (x)) \\
\bf d \rm (z)=\rm BERT_d(z), \ \bf q \rm (x)=\rm BERT_q(x)\]

<ul>
  <li>$\bf d \rm (z)$: a dense representation of a document produced by a document encoder based on $\rm BERT_{BASE}$.</li>
  <li>$\bf q \rm (x)$: a query representation produced by a query encoder based on $\rm BERT_{BASE}$.</li>
  <li><span style="background-color:#fff5b1">Maximum inner product search (MIPS)</span>: caculates top-k $p_\eta(\cdot\mid x)$ approximately in sub-linear time.</li>
  <li><span style="background-color:#fff5b1">Non-parametric memory</span>: the index of the document. The retriever is trained to retrieve documents containing answers to TriviaQA questions and Natural Questions.</li>
</ul>

<p><strong>Generator</strong> $p_\theta(y_i\mid x,z,y_{1:i-1})$ can be any encoder-decoder model, based on BART in the paper.</p>
<ul>
  <li>$\rm BART_{large}$ is used: a pre-trained seq2seq transformer with 400M parameters, pre-trained using a denoising objective with various noising functions.</li>
  <li>The input $x$ and the retrieved document $z$ are concatenated and then inputted into $\rm BART$ model to generate the output.</li>
  <li><span style="background-color:#fff5b1">Parametric memory</span>: $\rm BART$ generator parameters $\theta$.</li>
</ul>

<p><br /></p>

<h2 id="training">Training</h2>

<p>The retriever and generator are trained jointly without direct supervision on which document should be retrieved.</p>
<ul>
  <li>Objective: Minimize the negative marginal log-likelihood of each target with a corpus of input/output pairs $(x_j, y_j)$, $\sum_j-\log(p(y_j\mid x_j))$.
    <ul>
      <li>Adam optimizer.</li>
    </ul>
  </li>
  <li>Fine-tuning only the query encoder $\rm BERT_q$ and the generator $\rm BART$ during training.
    <ul>
      <li>Updating the document encoder $\rm BERT_d$ is costly and ineffective
        <ul>
          <li>Requires periodic updating of the document index (as REALM).</li>
          <li>Not necessary for strong performance.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="decoding">Decoding</h2>

<p>For testing, RAG-Sequence and RAG-Token require different methos to approximate $\arg \max_y{p(y\mid x)}$.</p>

<p><strong>RAG-Sequence model</strong> utilizes beam search for each document $z$. It canâ€™t be solved with a single beam search, as the likelihood $p(y\mid x)$ does not break into a conventional per-token likelihood.</p>
<ul>
  <li>Each hypothesis of $z$ is scored by $p_\theta(y_i\mid x,z,y_{1:i-1})$.</li>
  <li>Some hypothesis $y$ included in the set of hypothesis $Y$ may not have appeared in the beams of all documents.</li>
  <li><span style="background-color:#fff5b1">Thorough Decoding</span>: To estimate the probability of $y$, (1) Run an additional forward pass for each $z$ where $y$ doesnâ€™t appear in the beam, (2) multiply the generator probability with $p_\eta(z\mid x)$, and (3) sum the probabilities across beams.</li>
  <li><span style="background-color:#fff5b1">Fast Decoding</span>: For efficient decoding, Approximate $p_\theta(y\mid x,z_i) \approx 0$ where $y$ wasnâ€™t generated during beam search from $x, z_i$, avoiding additional forward passes once the candidate set $Y$ is generated.</li>
  <li>For longer output sequences, $\left\vert Y \right\vert$ can be large with many forward passes.</li>
</ul>

<p><strong>RAG-Token model</strong> is a basic autoregressive seq2seq generator with transition probability:</p>

\[p'_\theta(y_i\mid x,y_{1,i-1})=\sum_{z\in top-k(p(\cdot \mid x))}p_\eta(z_i \mid x)p_\theta(y_i\mid x,z_i,y_{1:i-1})\]

<p><br /></p>

<h1 id="experiments">Experiments</h1>

<p>The experiments were conducted on several datasets to evaluate the modelâ€™s performance in knowledge-intensive NLP tasks.</p>
<ul>
  <li>Wikipedia December 2018 dump was used as the non-parametric knowledge source.</li>
  <li>Wikipedia articles were split into 100-word chunks, totaling 21M documents.</li>
  <li>An embedding for each document was calculated by the document encoder $\rm BERT_d$, and a single MIPS index was built with Hierarchical Navigable Small World approximation for fast retrieval.</li>
  <li>When retrieving the top $k$ documents for each query, $k\in {5,10}$ was considered for training, and set using dev data for test time.</li>
</ul>

<h2 id="tasks">Tasks</h2>

<ol>
  <li><strong>Open-domain Question Answering (QA)</strong>: an important real-world application and common testbed for knowledge-intensive tasks.
    <ul>
      <li>Text pairs $(x,y)$ are matched as questions and answers.</li>
      <li>RAG is trained to minimize the negative log-likelihood of answers.</li>
      <li>Close-book QA is also a compared task: generating answers without retrieving but purely with parametric knowledge.</li>
      <li>Datasets: Natural Questions, TriviaQA, WebQuestions, CuratedTREC</li>
    </ul>
  </li>
  <li><strong>Abstractrive Question Answering</strong>: tests natural language generation (NLG) ability with free-form and abstractive cases.
    <ul>
      <li>Use MSMARCO NLG Task v2.1: only the question and answers, not existing gold passages in the dataset, treated as an open-domain abstractive QA task.</li>
    </ul>
  </li>
  <li><strong>Jeopardy Question Generation</strong>: evaluates the generation ability in a non-QA setting.
    <ul>
      <li>Jeopardy: guessing an entity from a fact about that entity.
        <ul>
          <li>e.g., â€œIn 1986 Mexico scored as the first contry to host this international sport competition twice.â€ where the answer is â€œThe World Cupâ€.</li>
        </ul>
      </li>
      <li>Jeopardy questions are precise and factual, making it a challenging, knowledge-intensive task to generate them conditioned on the anser entities.</li>
    </ul>
  </li>
  <li><strong>Fact Verification</strong> (FEVER): a retrieval problem coupled with an challenging entailment reasoning task.
    <ul>
      <li>Requires classifying whether a text is supported or refuted by Wikipedia or whether thereâ€™s not enough information to decide.</li>
      <li>Provides an appropriate testved for exploring a modelâ€™s ability to handle classification rather than generation.</li>
      <li>Two varients: the 3-way classification (supports/refutes/not enough) and the 2-way (support/refutes).</li>
    </ul>
  </li>
</ol>

<p><br /></p>

<h1 id="results">Results</h1>

<p>The results demonstrated that both RAG-Sequence and RAG-Token models outperformed baseline models across various datasets and tasks.</p>

<h2 id="open-domain-qa">Open-Domain QA</h2>

<p align="center">
    <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-11-05-rag/table1_2.png?raw=true" style="zoom: 100%;" />
</p>

<ul>
  <li>RAG models significantly outperformed the baselines, showing higher EM and F1 scores.</li>
  <li>The RAG-Token model, in particular, performed well due to its ability to integrate detailed information from multiple documents.</li>
</ul>

<p><br /></p>

<h2 id="abstractive-question-answering">Abstractive Question Answering</h2>

<p align="center">
    <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-11-05-rag/table3.png?raw=true" style="zoom: 100%;" />
</p>

<ul>
  <li>RAG models achieved SOTA performance, even though many questions are unanswerable without the gold passages.</li>
  <li>RAG models hallucinated less and generated more factually correct and diverse text compared to BART (Table 3).</li>
</ul>

<p><br /></p>

<h2 id="jeopardy-question-generation">Jeopardy Question Generation</h2>

<p align="center">
    <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-11-05-rag/table4_5.png?raw=true" style="zoom: 100%;" />
</p>
<p>
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-11-05-rag/fig2.png?raw=true" style="zoom: 100%;" />
</p>

<ul>
  <li>Both of RAG models outperformed BART on Q-BLEU-1 (Table 2).</li>
  <li>Human evaluators indicate that RAG-generated content was more factual in 42.7% of cases, demostrating the effectiveness of RAG over the SOTA generation model (Table 4).</li>
  <li>RAG-Token model performed better than RAG-Sequence, combining content from several documents effectively (Fig 2).</li>
  <li>The generatorâ€™s the parametric knowledge sufficed to complete the generation after initially referencing the document (Fig 2).</li>
</ul>

<p><br /></p>

<h2 id="fact-verification">Fact Verification</h2>

<ul>
  <li>For 3-way classification, RAG achieved scores within 4.3% of SOTA models trained with intermediate retrieval supervision for a specific domain.</li>
  <li>For 2-way classification, RAG achieved performance within 2.7% of the base model, SotA, which were trained to classify true of false given the gold evidences.</li>
  <li>The documents retrieved by RAG are overlapped significantly with FEVERâ€™s gold evidence.</li>
</ul>

<p><br /></p>

<h2 id="additional-results">Additional Results</h2>

<ol>
  <li>
    <p><strong>Generation Diversity</strong>: When investigating generation diversity by calculating the ratio of distinct ngrams to total ngrams generated by different models, RAG models generated more diverse outputs compared to BART. RAG-Sequence produced slightly more diverse outputs than RAG-Token (Table 5).</p>
  </li>
  <li><strong>Retrieval Ablations</strong>: Freezing the retriever during training resulted in lower performance compared to the original RAG models. Replacing the retriever with a BM25 system showed that learned retrieval improved performance for all task (table 6).
    <p align="center">
    <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-11-05-rag/table6.png?raw=true" style="zoom: 100%;" />
</p>
  </li>
  <li>
    <p><strong>Index hot-swapping</strong>: Demonstrated the advantage of non-parametric memory by using an index from Wikipedia dump from December 2016. RAG models still answered 70% of questions correctly, showing that knowledge can be updated simply by replacing the non-parametric memory.</p>
  </li>
  <li><strong>Effect of Retrieving more documents</strong>: Adjusting the number of retrieved documents at test time showed improved performance up to a certain point, demonstrating the benefits of retrieveing more relevant documents (fig 3).
    <p align="center">
    <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-11-05-rag/table6.png?raw=true" style="zoom: 100%;" />
</p>
  </li>
</ol>

<p><br /></p>

    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$$', '$$$'], ['\\[', '\\]'] ],
        processEscapes: true,
      }
    });
    MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="https://alatteaday.github.io/papers/2023/09/15/STraTS/">
        [Paper] Self-Supervised Transformer for Sparse and Irregularly Sampled Multivariate Clinical Time-Series (ACM 2022)
      </a>
    </h1>
    <!--<span class="post-date">15 Sep 2023</span>-->
    <p class="post-date">15 Sep 2023&nbsp;&nbsp;&nbsp;&nbsp;
      
        
          
            <span class="tag" data-tag="bio">
              <a href="https://alatteaday.github.io/tags/?tag=bio">
                #bio
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="ehr">
              <a href="https://alatteaday.github.io/tags/?tag=ehr">
                #ehr
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="transformer">
              <a href="https://alatteaday.github.io/tags/?tag=transformer">
                #transformer
              </a>
            </span>
            
        
      
    </p>
    <!--
    
    -->
    <p>Tipirneni, Sindhu, and Chandan K. Reddy. â€œSelf-supervised transformer for sparse and irregularly sampled multivariate clinical time-series.â€ <em>ACM Transactions on Knowledge Discovery from Data (TKDD)</em> 16.6 (2022): 1-17.</p>

<p><a href="https://dl.acm.org/doi/full/10.1145/3516367">Paper Link</a></p>

<h2 id="points">Points</h2>

<p><strong>Self-supervised Transformer for Time-Series (STraTS) model</strong></p>

<ul>
  <li>
    <p>Using observation triplets as time-series components: avoids the problems faced by aggregation and imputation methods for sparse and sporadic multivariate time-series</p>
  </li>
  <li>
    <p>Continuous Value Embedding: encodes continuous time and variable values without the need for discretization</p>
  </li>
  <li>
    <p>Transformer-based model: learns contextual triplet embeddings</p>
  </li>
  <li>
    <p>Time series forecasting as a proxy task: leverages unlabeled data to learn better generalized representations</p>
  </li>
</ul>

<h2 id="background">Background</h2>

<p>Problems</p>

<ul>
  <li>Multivariate time-series data are frequently observed in critical care settings and are typically characterized by sparsity (missing information) and irregular time intervals.</li>
  <li>Existing approaches, such as aggregation or imputation of values, suppress the fine-grained information and add undesirable noise/overhead into the model.</li>
  <li>The problem of limited availability of labeled data is easily observed in healthcare applications.</li>
</ul>

<p>The clinical domain portrays a unique set of challenges:</p>

<ul>
  <li>Missingness and Sparsity: Not all the variables are observed for every patient. Also, the time-series matrices are very sparse.</li>
  <li>Irregular time intervals and Sporadicity: Not all clinical variables are measured at regular time intervals. The measurements may occur sporadically in time depending.</li>
  <li>Limited labeled data: expensive and even more limited for specific tasks.</li>
</ul>

<p>Existing methods</p>

<ul>
  <li>Aggregation: could suppress important fine-grained information</li>
  <li>Imputation/Interpolation: not reasonable as not considering the domain knowledge about each variable</li>
</ul>

<h2 id="method">Method</h2>

<p><strong>Self-supervised Transformer for Time-Series (STraTS)</strong></p>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-09-15-strats/1_fig3.png?raw=true" alt="" /></p>

<h3 id="embeddings">Embeddings</h3>

<p><strong>Triplet Emgeddings</strong> = Feature embedding + Value embedding + Time embedding
\(T=\{(t_i, j_i, u_i)\}^n_{i=1}\\
e_i=e_i^f+e_i^v+e_i^t\)
<strong>Continuous Value Embedding (CVE)</strong></p>

<p>For continuous values of feature values and times</p>

<p>A one-to-many Feed-Forward Network
\(FFN(x) = U tanh(Wx+b)\)</p>

<ul>
  <li>
    <p>Feature embeddings $e_i^f$: obtained from a simpole lookup table</p>
  </li>
  <li>
    <p>Value embeddings $e_i^v$ and Time embeddings$e_i^t$: through CVE</p>
  </li>
</ul>

<p><strong>Demographics Embedding</strong></p>

<p>the prediction models performed better when demographics were processed separately.
\(e^ğ‘‘ = ğ‘¡ğ‘ğ‘›â„(W^ğ‘‘_2ğ‘¡ğ‘ğ‘›â„(W^ğ‘‘_1d + b^ğ‘‘_1) + b^ğ‘‘_2) âˆˆ R^d\)
where the hidden layer has a dimension of 2d</p>

<h3 id="self-supervision">Self-Supervision</h3>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-09-15-strats/2_fig2.png?raw=true" alt="" /></p>

<p>Pre-training Tasks: Both masking and forecasting as pretext tasks for providing self-supervision</p>

<p>The forecasitng improved the results on target tasks</p>

<p>The loss is:
\(L_{ss}=\frac{1}{|N'|}\sum_{k=1}^{N'}\sum_{j=1}^{|F|}m_j^k\Big(\tilde{z}_j^k-z_j^k\Big)^2\)</p>

<h3 id="interpretability">Interpretability</h3>

<p>I-STraTS: an interpretable version of STraTS</p>

<ul>
  <li>The output can be expressed using a linear combination of components that are derived from individual features</li>
</ul>

<p>Differences with STraTS</p>

<ul>
  <li>Combine the initial triplet embeddings in Fusion Self-attention module</li>
  <li>Directly use the raw demographics vector as the demographics embedding</li>
</ul>

\[\tilde{y}=sigmoid\Big(\sum_{j=1}^{D}{\bold{w}_0[j]d[j]+\sum_{i=1}^{n}\sum_{j=1}^{d}\alpha_i\bold{w}_o[j+D]\bold{e}_i[j]+b_o}\Big)\]

<h2 id="experiments">Experiments</h2>

<p>Target Task: Prediction of in-hospital mortality</p>

<p>Datasets: 2 EHR datasets; MIMIC-III and PhysioNet Challenge 2012</p>

<ul>
  <li>MIMIC-III: 46,000 patients</li>
  <li>PhysioNet-2012: 11,988 patients</li>
</ul>

<p>Baselines: Gated Recurrent Unit (GRU), Temporal Convolutional Network (TCN), Simply Attend and DIagnose (SaND), GRU with trainable Decays (GRU-D), Interpolation-prediction Network (InterpNet), Set Functions for Time Series (SeFT)</p>

<ul>
  <li>Used 2 dense layers for demographics encoding</li>
  <li>Concatenated it to the time-series representation before the last dense layer</li>
</ul>

<p>Metrics</p>

<ul>
  <li>ROC-AUC: Area under ROC curve</li>
  <li>PR-AUC: Area under precision-recall curve</li>
  <li>min(Re, Pr): the max of â€˜min of recall and precisionâ€™ across all thresholds</li>
</ul>

<h3 id="prediction-performance">Prediction Performance</h3>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-09-15-strats/3_table4.png?raw=true" style="zoom:80%;" /></p>

<ul>
  <li>Trained each model using 10 different random samplings of 50% labeled data from the train and validation sets</li>
  <li>STraTS uses the entire labeled data and additional unlabeled data if avaliable</li>
  <li>STraTS achieves the best performance</li>
  <li>GRU showed better performance than interpolation-based models (GRU-D, InterpNet) on the MIMIC-III dataset, which was not expected</li>
</ul>

<p><strong>Generalizability test of models</strong></p>

<p>Lower propotions of labeled data can be observed in real-world when there are several right-censord samples.</p>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-09-15-strats/4_fig5.png?raw=true" alt="" /></p>

<ul>
  <li>STraTS has an advantage compared to others in scarce labeled data settings, which can be attributed to self-supervision</li>
</ul>

<h3 id="ablation-study">Ablation Study</h3>

<p>Compared STraTS and I-STraTS with and without self-supervision: â€˜ss+â€™ and â€˜ss-â€˜ indicate each case</p>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-09-15-strats/5_table5.png?raw=true" style="zoom:80%;" /></p>

<ul>
  <li>I-STraTS showed slightly worse performance as constrained its representations</li>
  <li>Adding self-supervision improves performance of both models</li>
  <li>I-STraTS(ss+) outperforms STraTS(ss-): self-supervision can compensate the performance which could get lower by introducing interpretability</li>
</ul>

<h3 id="interpretability-1">Interpretability</h3>

<p>How I-STraTS explains its predictions</p>

<p>A case study: a 85 yrs old female patient from MIMIC-III</p>

<ul>
  <li>expired on the 6th day after ICU admission</li>
  <li>had 380 measurements corresponding to 58 time-series variables</li>
</ul>

<p>The model predicts the probability of her in-hospital mortality as 0.94 using only the data collected the first day</p>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-09-15-strats/6_table6.png?raw=true" alt="" /></p>

<ul>
  <li>Average contribution score: the average score along with the range, for multiple observations, or value, for only one observation</li>
  <li>The top 5 variables are the most important factors in predicting she â€˜s at high risk of mortality that the model observed</li>
</ul>

<p>&amp;rarr Can be helpful to identify high-risk patients and also understand the contributing factors and make better diagnoses, especially at the early stages of treatment</p>

    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$$', '$$$'], ['\\[', '\\]'] ],
        processEscapes: true,
      }
    });
    MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="https://alatteaday.github.io/study/2023/08/29/demensiapapers/">
        [Study] ì•Œì¸ í•˜ì´ë¨¸ ì¹˜ë§¤ì˜ ATN ë°”ì´ì˜¤ë§ˆì»¤ ê°„ ê´€ê³„ ì •ë¦¬
      </a>
    </h1>
    <!--<span class="post-date">29 Aug 2023</span>-->
    <p class="post-date">29 Aug 2023&nbsp;&nbsp;&nbsp;&nbsp;
      
        
          
            <span class="tag" data-tag="bio">
              <a href="https://alatteaday.github.io/tags/?tag=bio">
                #bio
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="brainImaging">
              <a href="https://alatteaday.github.io/tags/?tag=brainImaging">
                #brainImaging
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="demensia">
              <a href="https://alatteaday.github.io/tags/?tag=demensia">
                #demensia
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="atn">
              <a href="https://alatteaday.github.io/tags/?tag=atn">
                #atn
              </a>
            </span>
            
        
      
    </p>
    <!--
    
      Docker image ë° containerì™€ ê´€ë ¨í•˜ì—¬ ìì£¼ ì‚¬ìš©ë˜ëŠ” ëª…ë ¹ì–´ë¥¼ ì •ë¦¬í•´ë´…ë‹ˆë‹¤.
    
    -->
    <h2 id="ai-ì „ê³µìì˜-ì•Œì¸ í•˜ì´ë¨¸-ì¹˜ë§¤-ê´€ë ¨-brain-imaging-ë…¼ë¬¸-ìŠ¤í„°ë””">AI ì „ê³µìì˜ ì•Œì¸ í•˜ì´ë¨¸ ì¹˜ë§¤ ê´€ë ¨ Brain Imaging ë…¼ë¬¸ ìŠ¤í„°ë””</h2>

<p>Amyloid Beta(A), Tau(T), Neurodegeneration(N)ê³¼ ê´€ë ¨ëœ Alzheimerâ€™s Disease(AD) ê¸°ì „ì— ëŒ€í•´ ì´í•´í•˜ê¸° ìœ„í•˜ì—¬ ë‹¤ìŒì˜ ë…¼ë¬¸ë“¤ì„ ì½ê³  ì •ë¦¬í•œ ë‚´ìš©ì…ë‹ˆë‹¤. ê¸°ë°˜ ì§€ì‹ì´ ì—†ì–´ ì‹œê° ìë£Œì™€ ì‚¬ì „ì„ ì°¾ì•„ê°€ë©° ì½ì—ˆìŠµë‹ˆë‹¤. pdfëŠ” ì°¾ì•„ë³¸ ì´ë¯¸ì§€ì™€ í•„ê¸°í•œ ë‚´ìš©ì´ ë‹´ê¸´ ë…¼ë¬¸ íŒŒì¼ì…ë‹ˆë‹¤.</p>

<p>Ittner, Lars M., and JÃ¼rgen GÃ¶tz. â€œAmyloid-Î² and tauâ€”a toxic pas de deux in Alzheimerâ€™s disease.â€ <em>Nature Reviews Neuroscience</em> 12.2 (2011): 67-72. <a href="https://www.nature.com/articles/nrn2967">link</a> <a href="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-08-29-demensiapapers/nrn2967.pdf">pdf</a></p>

<p>Vogel, Jacob W., et al. â€œFour distinct trajectories of tau deposition identified in Alzheimerâ€™s disease.â€ <em>Nature medicine</em> 27.5 (2021): 871-881. <a href="https://www.nature.com/articles/s41591-021-01309-6">link</a> <a href="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-08-29-demensiapapers/s41591-021-01309-6.pdf">pdf</a></p>

<p>Lee, Wha Jin, et al. â€œRegional AÎ²-tau interactions promote onset and acceleration of Alzheimerâ€™s disease tau spreading.â€ <em>Neuron</em>110.12 (2022): 1932-1943. <a href="https://pubmed.ncbi.nlm.nih.gov/35443153/">link</a> <a href="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-08-29-demensiapapers/regional_onset.pdf">pdf</a></p>

<hr />

<p>Amyloid Beta(A)ëŠ” ë‰´ëŸ°ì— ì˜í•´ ìƒì„±ë˜ëŠ” Amyloid Precursor Protein(APP)ì´ í”„ë¡œí…Œì•„ì œì— ì˜í•´ 4ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ ì§ˆ ë•Œ ìƒê¸°ëŠ” í©íƒ€ì´ë“œ ì¤‘ í•˜ë‚˜ë¡œ,</p>

<p>ë‰´ëŸ° ê·¼ì²˜ì— ì¡´ì¬í•˜ì—¬ ê¸°ëŠ¥ ì¥ì• ë¥¼ ì•¼ê¸°í•˜ëŠ” ê²ƒìœ¼ë¡œ ì•Œë ¤ì¡Œë‹¤. Aì˜ ì¹¨ì°©ì€ Alzheimerâ€™s Disease(AD) ë°œë³‘ 10-20ë…„ ì „ë¶€í„° ì´ë¤„ì§„ë‹¤.</p>

<ul>
  <li>
    <p>AëŠ” dimers, oligomers, fibrils ë“±ì— ì´ì–´ plaqueë¥¼ í˜•ì„±í•œë‹¤. Aê°€ ì–´ëŠ í˜•íƒœì—ì„œ toxicityë¥¼ ê°–ê¸° ì‹œì‘í•˜ëŠ”ì§€ëŠ” í™•ì‹¤í•˜ì§€ ì•Šë‹¤. í•­ ì•„ë°€ë¡œì´ë“œ ì¹˜ë§¤ ì¹˜ë£Œì œëŠ” ì´ plaqueì˜ ê°ì†Œì™€ ì¦ì‹ ë° ìƒì„± ë°©ì§€ë¥¼ ëª©ì ìœ¼ë¡œ í•œë‹¤.</p>
  </li>
  <li>
    <p>Aì˜ toxicityëŠ” postsynaptic compartment, ì¦‰ dendrite(somatodendritic region)ë¥¼ ì£¼ ëŒ€ìƒìœ¼ë¡œ í•˜ì—¬ ì‘ìš©í•˜ê³ , íŠ¹ì • ìˆ˜ìš©ì²´ì˜ ì†ì„±ì— ë”°ë¼ ì„¸í¬ë§‰ì„ í†µí•´ ê°„ì ‘ì ìœ¼ë¡œ ë‰´ëŸ°ì— ì˜í–¥ì„ ë¼ì¹  ìˆ˜ ìˆë‹¤. ëŒ€í‘œì ì¸ íŠ¹ì • ìˆ˜ìš©ì²´ë¡œ NMDARì´ ìˆë‹¤.</p>
  </li>
</ul>

<p>Tau(T)ëŠ” ì‹ ê²½ ì„¸í¬ì—ì„œ microtubuleê³¼ ê²°í•©í•˜ëŠ” ë‹¨ë°±ì§ˆë¡œ, ì£¼ë¡œ axonì— ì¡´ì¬í•˜ì—¬ microtubuleì˜ ì•ˆì •í™” ë° axonal transitionì„ ì¡°ì ˆí•˜ëŠ” ì—­í• ì„ í•œë‹¤.</p>

<p>ì •ìƒ ìƒíƒœì˜ ë‰´ëŸ°ì˜ dendriteì—ë„ ì†ŒëŸ‰ ì¡´ì¬í•œë‹¤.</p>

<p>TëŠ” Aì— ì˜í•´ ê³¼ì¸ì‚°í™”ë˜ê³ (hyperphosphorylated Tau), ê³¼ì¸ì‚°í™”ëœ TëŠ” Neurofibrillary Tangle(NFT)ë¥¼ í˜•ì„±í•œë‹¤.</p>

<ul>
  <li>Tì˜ ê³¼ì¸ì‚°í™”ëŠ” microtubule í˜•ì„±ì„ ë°©í•´í•˜ì—¬ ë‰´ëŸ°ì˜ ê¸°ëŠ¥ì„ ë°©í•´í•œë‹¤.</li>
  <li>NFTëŠ” Somatodendritic regionì—ì„œ ë§ì´ ê´€ì°°ëœë‹¤. Tì˜ levelì´ ë†’ì•„ì§€ë©´ Tê°€ dendriteì—ì„œ ë§ì´ ê´€ì°°ëœë‹¤.</li>
</ul>

<p>Dendriteì—ì„œ TëŠ” ê·¸ê³³ì— ìœ„ì¹˜í•œ ì—¬ëŸ¬ ë‹¨ë°±ì§ˆê³¼ ìƒí˜¸ì‘ìš©í•˜ì—¬ ê²°ê³¼ì ìœ¼ë¡œ ë‰´ëŸ°ì´ Aì˜ toxicityì— ì•½í•´ì§€ê²Œ ë§Œë“ ë‹¤.</p>

<ul>
  <li>Tê°€ ì¸ì‚°í™”ë˜ë©´ Tyrosine protein kinasen FYNê³¼ ê°•í•˜ê²Œ ì‘ìš©í•œë‹¤. ê³¼ì¸ì‚°í™”ëœ Tê°€ dendriteì—ì„œ ì¦ê°€í•¨ì— ë”°ë¼ FYNë„ Somaì—ì„œ ì¦ê°€í•œë‹¤.</li>
  <li>FYNì€ NMDARì„ ì¸ì‚°í™”í•œë‹¤. ì¸ì‚°í™”ëœ NMDARì€ Postsynaptic Density Protein 95(PDS95)ì™€ ìƒí˜¸ì‘ìš©í•œë‹¤.</li>
  <li>ì´ê²ƒì˜ ê²°ê³¼ë¡œ NMDARì˜ excitotoxicityê°€ ë‚˜íƒ€ë‚œë‹¤(í¥ë¶„ë…ì„±ìƒíƒœ). ìˆ˜ìš©ì²´ì˜ excitotoxicityë¡œ Aì˜ toxicityì— ë‰´ëŸ°ì´ ë¯¼ê°í•´ì§€ê²Œ ëœë‹¤.</li>
</ul>

<p>ê²°ê³¼ì ìœ¼ë¡œ Aì™€ TëŠ” ë‰´ëŸ°ì„ ì•½í™”ì‹œí‚¤ëŠ” ë°ì— ìˆì–´ ì„œë¡œ ì‹œë„ˆì§€ë¥¼ ê°–ëŠ”ë‹¤. AëŠ” Tì˜ ê³¼ì¸ì‚°í™”ë¥¼ ì´‰ì§„í•˜ê³ , ê³¼ì¸ì‚°í™”ëœ TëŠ” ë‰´ëŸ°ì´ Aì˜ toxicityì— ì•½í•´ì§€ê²Œ ë§Œë“ ë‹¤.</p>

<p>ì´ ì‹œìŠ¤í…œì—ì„œ Aì™€ TëŠ” ì„¸í¬ì˜ ë‹¤ë¥¸ ë¶€ë¶„(ê°ê° Complex I, Complex IV)ì— ì•…ì˜í–¥ì„ ë¼ì³ ë¯¸í† ì½˜ë“œë¦¬ì•„ í˜¸í¡ì„ ë°©í•´í•˜ê³ , ê²°êµ­ Neurodegeneration(N)ì„ ì•¼ê¸°í•œë‹¤.</p>

<p>ë”°ë¼ì„œ Aì˜ ì¹¨ì°©ê³¼ Tì˜ ì „íŒŒëŠ” ADì˜ ì¤‘ìš”í•œ ìš”ì¸ì´ë‹¤.</p>

<p>Tì˜ ì „íŒŒ ì–‘ìƒì€ Braak Staging Systemìœ¼ë¡œ ì²´ê³„í™”ëœ ë°” ìˆë‹¤.</p>

<ul>
  <li>Transentorhinal cortex â†’ medial and basal temporal lobe â†’ neocortical associative regions â†’ unimodal sensory and motor cortex</li>
</ul>

<p>ê·¸ëŸ°ë° ì´ systemì— ë¶€í•©í•˜ì§€ ì•ŠëŠ” ì „íŒŒ ì–‘ìƒ ë˜í•œ ê´€ì°°ë˜ì—ˆë‹¤. Tì˜ ì „íŒŒ ì–‘ìƒì„ ë³‘ì˜ ì§„í–‰ê³¼ ë‡Œ ì˜ì—­ì˜ ì‹œê³µê°„ì  ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¥˜í•˜ì—¬ 4ê°€ì§€ subtypeìœ¼ë¡œ ì •ì˜í•  ìˆ˜ ìˆë‹¤.</p>

<ul>
  <li>S1 limbic (Braak system), S2 MTL, S3 posterior, S4 Lateral Temporal</li>
</ul>

<p>ì¹¨ì°©ëœ AëŠ” Tì˜ ì „íŒŒì— ì˜í–¥ì„ ì¤€ë‹¤.</p>

<ul>
  <li>AëŠ” heteromodal association cortexì— ì¹¨ì°©ë˜ê³ , Tì˜ ì „íŒŒëŠ” entorhinal cortex(EC)ì—ì„œ ì‹œì‘ë˜ì–´ ì ì°¨ ë‡Œ ì „ë°˜ìœ¼ë¡œ í¼ì§„ë‹¤. ( â† Braak system; S1 type ? )</li>
  <li>Remote Interation: Aì™€ Tê°€ ê°™ì€ ì˜ì—­ì— ìˆì§€ ì•Šì€ ìƒíƒœì—ì„œ, ë¨¼ì € Aê°€ ì—°ê²°ëœ ë‰´ëŸ°ì„ í†µí•´ì„œ EC ì˜ì—­ì— ìˆëŠ” Tì— ì˜í–¥ì„ ì¤€ë‹¤. Aì˜ ì˜í–¥ìœ¼ë¡œ TëŠ” ì ì°¨ ì£¼ìœ„ ì˜ì—­ìœ¼ë¡œ í™•ì‚°ëœë‹¤.</li>
  <li>Local Interaction: Tê°€ Aì™€ ì§ì ‘ì ìœ¼ë¡œ ì ‘ì´‰ë˜ì–´ ìˆëŠ” ë‰´ëŸ°ì— ì „íŒŒë˜ì–´ ë§Œë‚¨ìœ¼ë¡œì„œ Tì˜ ì „íŒŒê°€ ê°€ì†í™”ëœë‹¤(acceleration). í•´ë‹¹ ë‡Œ ì˜ì—­ì€ Internal Temporal Gyrus(ITG)ì´ë‹¤ (propagation hub).</li>
  <li>T ì „íŒŒì˜ accelerationì´ ì§„í–‰ë˜ë©´ ë‡Œ ì „ë°˜ì—ì„œ Aì™€ Tì˜ ìƒí˜¸ì‘ìš©ì´ ì¼ì–´ë‚˜ê²Œ ë˜ì–´ Nê³¼ ADì˜ ì•…í™”ë¥¼ ë§‰ê¸° ì–´ë µë‹¤.</li>
</ul>

<p>Aì™€ Tì˜ PET ë°ì´í„°ì™€ MRI ë°ì´í„°ë¥¼ ë³‘ì˜ ì§„í–‰ì— ë”°ë¼ ì‚´í´ë³´ë©´</p>

<ul>
  <li>Aì˜ ì¹¨ì°©ë˜ëŠ” ì •ë„ëŠ” ë‡Œ ì „ë°˜ì— ê±¸ì³ ì ì  ì‹¬í•´ì§ˆ ê²ƒì´ê³ </li>
  <li>TëŠ” ë‡Œì˜ íŠ¹ì • ë¶€ë¶„ì—ì„œ ì‹œì‘í•˜ì—¬ ì ì°¨ í™•ì‚°ë˜ëŠ” ì–‘ìƒìœ¼ë¡œ ê´€ì°°ë˜ê³ </li>
  <li>Tì˜ ìŠˆí¼ ì „íŒŒê°€ ê´€ì°°ëœ ì´í›„ MRI ìƒ ì „ë°˜ì ì¸ ë‡Œ ìœ„ì¶•(N)ì˜ ì •ë„ê°€ ì‹¬í•˜ê²Œ ë‚˜íƒ€ë‚  ê²ƒì´ë‹¤.</li>
</ul>


    
  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="https://alatteaday.github.io/page5">Older</a>
  
  
    
      <a class="pagination-item newer" href="https://alatteaday.github.io/page3">Newer</a>
    
  
</div>

        
      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script src='/public/js/script.js'></script>
  </body>
</html>
