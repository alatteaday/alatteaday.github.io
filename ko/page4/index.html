<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!--site.title site.tagline-->
  <title>
    
      Coffee Chat &middot; Brewing AI Knowledge
    
  </title>

  
  <link rel="canonical" href="https://alatteaday.github.io/ko/page4/">
  

  <link rel="stylesheet" href="https://alatteaday.github.io/public/css/poole.css">
  <link rel="stylesheet" href="https://alatteaday.github.io/public/css/syntax.css">
  <link rel="stylesheet" href="https://alatteaday.github.io/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://alatteaday.github.io/public/favicon.ico/apple-touch-icon.png">
  <link rel="shortcut icon" href="https://alatteaday.github.io/public/favicon.ico/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="RSS" href="https://alatteaday.github.io/ko/atom.xml">

  
</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>Curation of studies, techs, ideas and a journey as a maching learning engineer</p>
  </div>

  <nav class="sidebar-nav">

    <a class="sidebar-nav-item" href="https://alatteaday.github.io/ko/about">About</a>
    <a class="sidebar-nav-item active" href="https://alatteaday.github.io/ko/">Home</a>
    <a class="sidebar-nav-item" href="https://alatteaday.github.io/ko/tags">Tags</a>

    

    
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
          <a class="sidebar-nav-item" 
          href="https://alatteaday.github.io/ko/about/">About</a>
        
        -->
        
      
    
      
    
      
        <!--
        
        -->
        
          <a class="sidebar-nav-item "
          href="https://alatteaday.github.io/ko/category/error/">Dev Tips & Fixes</a>
        
      
    
      
        <!--
        
        -->
        
          <a class="sidebar-nav-item "
          href="https://alatteaday.github.io/ko/category/papers/">Papers</a>
        
      
    
      
        <!--
        
        -->
        
          <a class="sidebar-nav-item "
          href="https://alatteaday.github.io/ko/category/study/">Study</a>
        
      
    
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
    <!--
    <a class="sidebar-nav-item" href="/ko/archive/v1.1.0.zip">Download</a>
    <a class="sidebar-nav-item" href="">GitHub project</a>
    <span class="sidebar-nav-item">Currently v1.1.0</span> 
    -->
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2024. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <!--site.title site.tagline-->
    <div class="wrap">
      <div class="masthead">
        <div class="container" >
          <h3 class="masthead-title">
            <a href="/ko/" title="Home">Coffee Chat</a>
            <small>Brewing AI Knowledge</small>
          </h3>
          <div class="lang-switcher">
    
    
        
            <a href=" /page4/">eng</a>
        
    

    
    
        kor
    

</div>
        </div>
      </div>

      <div class="container content">
        <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="https://alatteaday.github.io/ko/study/2023/12/26/mri2/">
        [LearnMRI] MR Modality 종류와 관찰 가능한 뇌 양상
      </a>
    </h1>
    <!--<span class="post-date">26 Dec 2023</span>-->
    <p class="post-date">26 Dec 2023&nbsp;&nbsp;&nbsp;&nbsp;
      
        
          
            <span class="tag" data-tag="bio">
              <a href="https://alatteaday.github.io/ko/tags/?tag=bio">
                #bio
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="brainImaging">
              <a href="https://alatteaday.github.io/ko/tags/?tag=brainImaging">
                #brainImaging
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="mri">
              <a href="https://alatteaday.github.io/ko/tags/?tag=mri">
                #mri
              </a>
            </span>
            
        
      
    </p>
    <!--
    
    -->
    <p><a href="https://alatteaday.github.io/ko/study/2023/12/26/mri/">Spin echo 기법</a>에 따라 T1 강조 영상(T1 weighted image; T1WI)과 T2 강조 영상(T2 weighted image; T2WI)을 얻을 수 있다. 이들에 영상 조작을 더하여 다양한 MR modality 영상을 생성할 수 있다. 영상마다 병변 조직의 신호 강도(signal intensity)가 달리 나타나므로, 강조되는 병변의 종류가 다르다.</p>

<p align="center">
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-12-25-mri/t1_t2_flair.png?raw=true" style="zoom: 50%;" />
</p>

<p><br /></p>

<h3 id="t1-강조-영상-t1-weighted-image-t1wi">T1 강조 영상 (T1-weighted image; T1WI)</h3>

<ul>
  <li>Spin echo: TR과 TE를 모두 짧게 준다
    <ul>
      <li>TR이 짧아지면 조직마다 다른 $Mz$의 90도 pulse 회복 시간(T1 relaxation time)이 강조된다. 어느 조직은 모두 회복되고, 어느 조직은 덜 된 상태로 두 번째 pulse의 영향을 받으면, 전자는 영향을 많이, 후자는 덜 받게 된다. 이 차이가 영상에 반영 된다.</li>
      <li>TE를 짧게 주어야 T2 relxation time 값에 영향을 덜 줌으로써 이를 통제할 수 있다.</li>
    </ul>
  </li>
  <li>Signal intensity:
    <ul>
      <li>Signal intensity가 T2-weighted image보다 높아 해부학적(anatomical) 구조물이 더 명확히 구별된다.</li>
      <li>피하지방(fat) 및 혈액(blood)은 밝게(hyperintense), 근육은 중간 정도의 밝기로, 수분(water)은 어둡게(hypointense) 보인다.</li>
      <li>골수(marrow)는 지방이 풍부하므로, 골피질(cortex)은 수분이 적으므로 hyperintense하게 나타난다.</li>
      <li>병변: 지방종, 아급성 출혈, 고단백질 함유 병소(점액낭종(mococele) 등)</li>
    </ul>
  </li>
  <li>Observe: 뇌 피질 형태(anatomical detail), 혈관 변화(vascular changes), 혈뇌장벽(blood-brain barrier) 손상 여부</li>
  <li>Feature: cortical thickness, choroid plexus (ChP)</li>
</ul>

<p><br /></p>

<h3 id="t2-강조-영상-t2-weighted-image-t2wi">T2 강조 영상 (T2-weighted image; T2WI)</h3>

<ul>
  <li>Spin echo: TR과 TE를 모두 길게 준다
    <ul>
      <li>TR을 길게 주어 T1 relaxation time에 영향을 덜 준다.</li>
      <li>TE가 길수록 조직마다 $Mxy$가 감소되는 수준의 차이가 강조되어 영상에 달리 표현된다.</li>
    </ul>
  </li>
  <li>Signal intensity:
    <ul>
      <li>수분(water)이 hyperintense한데, 병적 조직은 수분을 많이 함유하므로 병소(lesion)가 쉽게 관찰된다.
        <ul>
          <li>대부분의 병변은 T1에서는 저신호, T2에서는 고신호로 나타난다.</li>
          <li>수분 함유량이 많은 조직일 수록 hyperintense하다: 낭종 &gt; 부종 &gt; 정상 조직 순으로 밝게 보인다.</li>
        </ul>
      </li>
      <li>뇌척수액(cerebrospinal fluid; CSF)도 hyperintense하여 병변과 구분이 잘 되지 않는다.</li>
      <li>Muscle, fat, blood는 hypointense하다.</li>
    </ul>
  </li>
  <li>Observation: 병소(lesion), hypo 병변 (급성혈종, 진균구 등), 동맥 (정맥은 혈류 속도가 느려 환자마다 신호 강도가 다르다)</li>
  <li>Feature: <a href="https://alatteaday.github.io/ko/study/2023/12/26/mri3/">Perivascular space (PVS)</a></li>
</ul>

<p><br /></p>

<h2 id="flair-fluid-attenuation-inversion-recovery">FLAIR (Fluid Attenuation Inversion Recovery)</h2>

<ul>
  <li>T2에서 CSF를 까맣게 처리한 이미지이다.</li>
  <li>Signal intensity: Non-free-flowing water는 hyperintense, fat은 hypointense로 나타난다.</li>
  <li>Observation: 뇌실(ventricle) 부근의 병소, 부종(edema, 부종은 정체된 수분이라 밝게 나타난다), 회백질의 차이(grey-white differentiation)</li>
  <li>Feature: lesion, <a href="https://alatteaday.github.io/ko/study/2023/12/26/mri3/">white matter hyperintensity (WMH)</a></li>
</ul>

<p><br /></p>

<h2 id="gre-gradient-echo-t2">GRE (Gradient Echo; T2*)</h2>

<p align="center">
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-12-25-mri/gre.png?raw=true" style="zoom: 25%;" />
</p>

<ul>
  <li>Signal intensity: 상자성체 물질(paramegnetic substances, blood, calcium, metal 등)이 hyperintense로 나타나, 철의 침착과 관련된 사항을 관찰하기 용이하다.</li>
  <li>Observation: 뇌출혈 초기/말기, 미만성 축삭손상(diffuse axonal injury)에서 보이는 microbleed 검출에 탁월
    <ul>
      <li>*diffuse axonal injury: 뇌진탕 등 뇌손상의 구성요소 중 하나, 축삭 손상으로 인해 외상 후 혼수상태를 보이는 특징이 있다.</li>
    </ul>
  </li>
  <li>Feature: bleeding</li>
</ul>


    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$$', '$$$'], ['\\[', '\\]'] ],
        processEscapes: true,
      }
    });
    MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="https://alatteaday.github.io/ko/study/2023/12/26/mri/">
        [LearnMRI] MRI 촬영 원리와 특징
      </a>
    </h1>
    <!--<span class="post-date">26 Dec 2023</span>-->
    <p class="post-date">26 Dec 2023&nbsp;&nbsp;&nbsp;&nbsp;
      
        
          
            <span class="tag" data-tag="bio">
              <a href="https://alatteaday.github.io/ko/tags/?tag=bio">
                #bio
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="brainImaging">
              <a href="https://alatteaday.github.io/ko/tags/?tag=brainImaging">
                #brainImaging
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="mri">
              <a href="https://alatteaday.github.io/ko/tags/?tag=mri">
                #mri
              </a>
            </span>
            
        
      
    </p>
    <!--
    
    -->
    <p>MRI와 MRI modalities, MRI에서 관찰 가능한 Alzheimer’s disease 관련 feature를 정리해봅니다.
<br /></p>

<h2 id="magnetic-resonance-imaging-mri">Magnetic Resonance Imaging (MRI)</h2>

<p>자석으로 구성된 장치에서 인체에 고주파를 쏘아 신체부위에 있는 수소원자핵을 공명시켜 각 조직에서 나오는 신호의 차이를 디지털 정보로 변환한 이미지</p>

<p><br /></p>

<h2 id="mri-촬영-원리">MRI 촬영 원리</h2>

<p>인체 조직은 물을 많이 포함하고 있다. 물의 수소원자핵(hydrogen nucleus)은 자성을 갖는다. 이 수소원자핵에 고주파를 발사하면 이를 공명시킬 수 있다. 고주파(radiofrequency; RF)를 순간적으로 발사하고 끊으면(RF pulse), 원자핵이 고주파 신호를 흡수했다가 방출한다(release). 여기서 MR 기기로 되돌아오는 신호의 크기 차이를 분석하고 극대화하여 2차원 영상으로 표현한 것이 MRI이다.</p>

<p>방출되는 신호의 크기와 파형은 물분자의 농도, 혈류, 주변 화학구조물과의 결합 상태 등에 따라 다르다. 조직 내 물이나 혈액 구성에 따라 T1 이완 시간(relaxation time)과 T2 이완 시간이 달라진다. 질병에 따라 이들 구성이 달라지므로, 질병에 따라 얻을 수 있는 신호가 다르다는 의미가 된다. 이 신호 변화를 달리 포착하여 <a href="https://alatteaday.github.io/ko/study/2023/12/26/mri2/">T1 강조 영상(weighted image; WI), T2WI, FLAIR 등 다양한 MRI</a>를 얻을 수 있다.</p>

<p align="center">
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-12-25-mri/mr_axis.png?raw=true" style="zoom: 40%;" align="center" />
</p>

<p>T1 relaxation time과 T2 relaxation time은 양성자(proton)에 RF pulse를 90도로 가한 후에 각각 다른 기준에 의해 측정된다. proton의 자기화를 종축($Mz$)에서 횡축으로 눕히면 $Mxy$ vector가 형성된다. $Mz$ vector가 0%, $Mxy$ vector가 100%가 되는 순간부터 T1, T2 relaxation time을 측정한다. 조직마다 두 relaxation time 모두 상이하게 나타난다.</p>

<p>T1 relaxation time은 $Mz$가 63%까지 회복하는 데에 걸리는 시간이다. 지방(fat) - 뇌세포 조직(brain tissue) - 뇌척수액(cerebrospinal fluid; CSF) 순으로 회복이 빠르다(T1 relaxation time이 빠르다).</p>

<p>T2 relaxation time은 $Mxy$가 37%까지 감소하는 데에 걸리는 시간으로, 자장의 세기에 별로 영향을 받지 않는다. Fat - brain tissue - CSF 순으로 신호가 빨리 감소한다.</p>

<p>T1 relaxation time이 짧은 조직은 T2 curve도 급격히 감소한다. 물과 지방은 T1과 T2에서 반대의 intensity를 갖는다 (opposite signal intensity).</p>

<p>Spin echo는 RF pulse를 90도와 180도로 주어 repetition time (TR)과 echo time (TE)을 조작하며 영상을 찍는 기법이다. TR은  90도 pulse에서 다음 90도 pulse까지의 시간, TE은 90도 pulse에서 신호를 얻을 때까지의 시간을 말한다. 영상 촬영 시 pulse를 여러 번 반복하므로, TR과 TE를 조작하여 <a href="https://alatteaday.github.io/ko/study/2023/12/26/mri2/">다양한 영상</a>을 얻을 수 있다.</p>

<p><br /></p>

<h2 id="mri의-장단점">MRI의 장단점</h2>

<p>장점</p>
<ul>
  <li>CT에 비해 연부 조직의 contrast가 더 잘 드러난다.</li>
  <li>해부학적, 생리학적, 기능적 정보 등을 관찰할 수 있다.</li>
</ul>

<p>단점</p>
<ul>
  <li>철자성 인공허상(ferromagnetic artifacts): 자장에 영향을 주는 금속물질 등이 체내 소량이라도 존재하면 자장의 균질성이 깨져 영상이 왜곡된다.</li>
  <li>금니나 기타 삽입 물질이 있으면 영상의 질이 떨어진다.</li>
</ul>

<p>금기: 자성에 영향을 받을 수 있는 신체 내 삽입물 등을 가진 환자에게는 사용하지 말아야 한다.</p>


    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$$', '$$$'], ['\\[', '\\]'] ],
        processEscapes: true,
      }
    });
    MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="https://alatteaday.github.io/ko/papers/2023/11/05/rag/">
        [Paper] Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (NIPS 2020)
      </a>
    </h1>
    <!--<span class="post-date">05 Nov 2023</span>-->
    <p class="post-date">05 Nov 2023&nbsp;&nbsp;&nbsp;&nbsp;
      
        
          
            <span class="tag" data-tag="llm">
              <a href="https://alatteaday.github.io/ko/tags/?tag=llm">
                #llm
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="transformer">
              <a href="https://alatteaday.github.io/ko/tags/?tag=transformer">
                #transformer
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="nlp">
              <a href="https://alatteaday.github.io/ko/tags/?tag=nlp">
                #nlp
              </a>
            </span>
            
        
      
    </p>
    <!--
    
    -->
    <p>Lewis, Patrick, et al. “Retrieval-augmented generation for knowledge-intensive nlp tasks.” <em>Advances in Neural Information Processing Systems</em> 33 (2020): 9459-9474.</p>

<p><a href="https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html">Paper Link</a></p>

<h1 id="points">Points</h1>

<ul>
  <li><strong>Retrieval Augmented Generation (RAG)</strong> 모델은 retriever와 generator를 결합한 구조로 knowledge-intense task 수행 능력이 향상되었다.</li>
  <li>RAG Variants: RAG-Sequence는 단일 문서를 사용해 output을 생성하고, RAG-Token 각 토큰을 생성하는 데 여러 문서를 통합한다.</li>
  <li>RAG 모델은 open-domain QA, abstractive QA, Jeopardy question generation, and fact verification에서 baseline 모델을 능가하는 결과를 보였다.</li>
  <li>RAG 모델은 non-parametric memory를 업데이트하는 간단한 방법으로 최신 자료를 쉽게 반영할 수 있는 실용적인 이점을 갖는다.</li>
</ul>

<p><br /></p>

<h1 id="background">Background</h1>

<ul>
  <li>Large pre-trained Language models (LLMs)은 자체 parameter에 사실 관련 지식을 저장하고, 이것을 지식 base로 사용한다.</li>
  <li>이러한 LLM은 자체적으로 이러한 지식을 담고 있는 메모리를 확장할 수 없고, 생성되는 output에 사실적인 통찰을 반영하거나 보장하기 어려우며, 나아가 hallucination 생성 가능성이 높다는 단점을 갖는다.</li>
  <li>최근 REALM과 ORQA 같은 hybrid 모델은 미분 가능한 retriever를 사용하여 지식을 수정하고 확장함으로서 이런 문제를 해결한다. 이것으로 특히 open-domain question answering (QA)에서 좋은 결과를 보였다.</li>
</ul>

<p><br /></p>

<h1 id="method">Method</h1>

<p align="center">
    <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-11-05-rag/fig1.png?raw=true" style="zoom: 100%;" />
</p>

<p>Retrieval-augmented generation (RAG)은 pre-trained generation 모델이 non-parametric memory를 사용해 보편적인 task를 수행할 수 있도록 fine-tuning 한다.</p>
<ul>
  <li>Parametric memory: pre-trained seq2seq transformer</li>
  <li>Non-parametric memory: Wikipedia로부터 pre-trained neural retriever를 통해 얻는 dense vector index.</li>
  <li>Dense passage retriever (DPR): input을 조건으로 latent document를 검색하는 retriever.</li>
  <li>BART: input과 latent document를 조건으로 output을 생성하는 generator. T5 등 다른 seq2seq 모델로 대체 가능하다. Retriever와 함께 fine-tuning 된다.</li>
  <li>Latent document: top-K 근사를 통해 output(시퀀스) 별 또는 토큰 별로 marginalizing 된다.
    <ul>
      <li>RAG-Sequence Model: 하나의 문서가 모든 토큰의 출처가 된다고 가정한다.</li>
      <li>RAG-Token Model: 여러 문서가 한 토큰을 생성하는 데 출처가 된다고 가정한다.</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="models">Models</h2>

<p>RAG 모델은 input 시퀀스 $x$를 사용해 text document $z$를 검색하고, 이를 target 시퀀스 $y$를 생성할 때 추가적인 문맥으로 사용한다. RAG 두 가지 구성 요소로 이루어진다:</p>
<ul>
  <li>Retriever $p_\eta(z\mid x)$: 쿼리인 $x$에 대한 문서들의 분포를 반환한다.
    <ul>
      <li>Truncated as top-K assumtion.</li>
    </ul>
  </li>
  <li>Generator $p_\theta(y_i\mid x,z,y_{1:i-1})$: 이전 토큰들 $y_{1:i-1}$과 현재 input $x$ 및 검색된 내용 $z$을 기반으로 현재 스텝의 토큰을 생성한다.
Retriever와 Generator는 검색된 문서를 latent variable로 취급하여 end-to-end로 학습된다. latent document를 marginalize 하기 위한 방법으로 RAG-Sequence와 RAG-Token 두 가지 방법이 제안되었다.</li>
</ul>

<p><br /></p>

<h2 id="rag-sequence-and-rag-token">RAG-Sequence and RAG-Token</h2>

<p><strong>RAG-Sequence Model</strong>: 검색된 동일한 문서를 사용해 전체 시퀀스를 생성한다.</p>

<ul>
  <li>검색된 문서는 top-k seq2seq 확률 $p(y\mid x)$을 얻기 위한 단일 latent variable로 간주된다.</li>
  <li>Retriever로 top-K 문서를 검색하고, Generator로 각 문서에 대해 output 시퀀스에 대한 확률을 계산한다.</li>
</ul>

\[p_{RAG-Sequence}(y\mid x)\approx \sum_{z\in top-k(p(\cdot|x))}{p_\eta(z|x)p_\theta(y_i|x,z)} \\ = \sum_{z\in top-k(p(\cdot|x))}{p_\eta(z|x)}\prod_i^N p_\theta(y_i|x,z,y_{1:i-1})\]

<ul>
  <li>Use cases: 요약과 같은 문서의 전체적인 맥락이 중요한 작업에 적합하다.</li>
</ul>

<p><strong>RAG-Token Model</strong>: 각 토큰을 생성할 때 다른 latent document를 사용한다.</p>
<ul>
  <li>Generator는 여러 문서에서 내용을 추출하여 output을 생성한다.</li>
  <li>Retriever는 top-K 문서를 검색하고 Generator는 각 문서에 대해 다음 output 토큰에 대한 분포를 계산한다.</li>
</ul>

\[p_{RAG-Token}(y|x)\approx \prod_i^N \sum_{z\in top-k(p(\cdot\mid x))}p_\eta(z\mid x)p_\theta(y_i\mid x,z_i,y_{1:i-1})\]

<ul>
  <li>Use cases: QA와 같이 여러 자료를 출처로 상세한 정보를 통합하는 작업에 적합하다.</li>
</ul>

<p><br /></p>

<h2 id="retriever-and-generator">Retriever and Generator</h2>

<p><strong>Retriever</strong> $p_\mu(z\mid x)$: bi-encoder 구조를 갖는 DPR을 기반으로 한다:</p>

\[p_\mu(z|x)\propto \exp(\bf d \rm (z)^\top \bf q \rm (x)) \\
\bf d \rm (z)=\rm BERT_d(z), \ \bf q \rm (x)=\rm BERT_q(x)\]

<ul>
  <li>$\bf d \rm (z)$: 문서에 대한 representation. $\rm BERT_{BASE}$ 기반 document encoder가 생성한다.</li>
  <li>$\bf q \rm (x)$: 쿼리에 대한 representation. $\rm BERT_{BASE}$ 기반 query encoder가 생성한다.</li>
  <li><span style="background-color:#fff5b1">Maximum inner product search (MIPS)</span>: top-k $p_\eta(\cdot\mid x)$를 sub-linear에 근접한 시간 내 계산하는 방법</li>
  <li><span style="background-color:#fff5b1">Non-parametric memory</span>: 문서의 인덱스. Retriever는 TriviaQA의 질문과 Natural Questions에 대해 답하는 데 필요한 문서를 검색하도록 학습된다.</li>
</ul>

<p><strong>Generator</strong> $p_\theta(y_i\mid x,z,y_{1:i-1})$: 이 연구에서는 BART를 기반으로 하나, 어떤 encoder-decoder 모델로도 대체될 수 있다.</p>
<ul>
  <li>$\rm BART_{large}$: 400M 파라미터를 갖는 pre-trained seq2seq transformer. 다양한 noising function과 denoising objective로 pre-training 되었다.</li>
  <li>Input $x$와 검색된 문서 $z$를 concatenate 하여 $\rm BART$ 모델에 입력하고 output을 생성한다.</li>
  <li><span style="background-color:#fff5b1">Parametric memory</span>: $\rm BART$ generator의 파라미터 $\theta$.</li>
</ul>

<p><br /></p>

<h2 id="training">Training</h2>

<p>Retriever와 generator는 어떤 문서를 검색해야 하는지에 대한 정답 없이 학습된다.</p>
<ul>
  <li>Objective: input/output 쌍 $(x_j, y_j)$의 negative marginal log-likelihood 최소화, $\sum_j-\log(p(y_j\mid x_j))$.
    <ul>
      <li>Adam optimizer 사용.</li>
    </ul>
  </li>
  <li>Query encoder $\rm BERT_q$와 generator $\rm BART$만 finetune 한다.
    <ul>
      <li>Document encoder $\rm BERT_d$ 업데이트는 비용이 많이 들고 비효율적이다.
        <ul>
          <li>Document index를 주기적으로 업데이트해야 한다.</li>
          <li>성능 향상에 그다지 유의미하지 않다.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="decoding">Decoding</h2>

<p>테스트 시, RAG-Sequence와 RAG-Token은 $\arg \max_y{p(y\mid x)}$를 근사하기 위한 서로 다른 방법을 필요로 한다.</p>

<p><strong>RAG-Sequence model</strong>: 각 문서 $z$에 대해 beam search를 사용한다. $p(y\mid x)$은 기존 보편적인 토큰별 확률로 분해할 수 없어 단일 beam search로 구할 수 없다.</p>
<ul>
  <li>각 $z$의 hypothesis는 $p_\theta(y_i\mid x,z,y_{1:i-1})$로 점수가 매겨진다.</li>
  <li>hypothesis 집합 $Y$에 포함된 일부 $y$는 모든 문서의 beam에서 나타나지 않을 수 있다.</li>
  <li><span style="background-color:#fff5b1">Thorough Decoding</span>: $y$의 확률을 추정하기 위해, $y$가 beam에 나타나지 않는  $z$ 각각에 대해 추가적으로 forward pass를 진행하고, generator의 확률을 $p_\eta(z\mid x)$와 곱한 뒤, beam의 확률을 더한다.</li>
  <li><span style="background-color:#fff5b1">Fast Decoding</span>: 후보 집합 $Y$가 생성되었을 때, forward pass를 방지하기 위해 $p_\theta(y\mid x,z_i) \approx 0$로 근사해 효율적으로 decoding을 수행한다. 이 방법은  $x, z_i$에서 beam search를 했을 때 $y$가 생성되지 않은 경우 유효하다.</li>
  <li>긴 output 시퀀스를 생성하는 경우, $\left\vert Y \right\vert$가 여러 forward pass를 수행하며 커질 수 있다.</li>
</ul>

<p><strong>RAG-Token model</strong>: transition 확률을 갖는 기본적인 autoregressive seq2seq generator와 같은 방식으로 작동한다:</p>

\[p'_\theta(y_i\mid x,y_{1,i-1})=\sum_{z\in top-k(p(\cdot \mid x))}p_\eta(z_i \mid x)p_\theta(y_i\mid x,z_i,y_{1:i-1})\]

<p><br /></p>

<h1 id="experiments">Experiments</h1>

<p>RAG 모델이 knowledge-intensive NLP task에서 효과적인지에 대한 성능을 평가하기 위해 다양한 task를 설정했다. 모델 관련 setting 사항은 다음과 같다:</p>
<ul>
  <li>Wikipedia December 2018 dump를 non-parametric knwoledge source로 사용했다.</li>
  <li>Wikipedia 문서를 100 단어씩 한 chunk로 나누어 총 2,100만 개 문서로 구성했다.</li>
  <li>Document encoder $\rm BERT_d$로 각 문서에 대한 임베딩을 구하고, 빠른 검색을 위해 Hierarchical Navigable Small World approximation을 사용해 단일 MIPS 인덱스를 구축했다.</li>
  <li>각 쿼리에 대해 top $k$개의 문서를 검색할 때, $k\in {5,10}$로 설정하여 학습과 테스트 시 반영했다.</li>
</ul>

<h2 id="tasks">Tasks</h2>

<ol>
  <li><strong>Open-domain Question Answering (QA)</strong>: 중요한 real-world application이자 보편적인 knowledge-intensive task이다.
    <ul>
      <li>텍스트 쌍 $(x,y)$는 질문과 답변에 매칭된다.</li>
      <li>RAG는 답변 생성 시 negative log-likelihood를 최소화하도록 학습된다.</li>
      <li>Close-book QA를 통한 비교도 진행: 검색 없이 오로지 모델에 내제된 parametric knowledge로 시퀀스를 생성한다.</li>
      <li>Datasets: Natural Questions, TriviaQA, WebQuestions, CuratedTREC</li>
    </ul>
  </li>
  <li><strong>Abstractrive Question Answering</strong>: 자유 형식이나 추상적인 경우에서의 natural language generation (NLG) 성능을 테스트한다.
    <ul>
      <li>MSMARCO NLG Task v2.1 사용: 원래 존재하는 gold passage는 배제하고, 질문과 답변만 사용하여 open-domain abstractive QA task를 구성했다.</li>
    </ul>
  </li>
  <li><strong>Jeopardy Question Generation</strong>: QA 상황이 아닌 경우의 생성 능력을 평가한다.
    <ul>
      <li>Jeopardy: 특정 entity에 대한 사실을 보고 entity를 추측하는 것.
        <ul>
          <li>예를 들어, “1986년 멕시코는 이 국제 스포츠 대회를 두 번 개최한 첫 번째 국가로 기록되었다.”라는 사실을 보고, 이 사실에 해당하는 entity인 “월드컵”을 추측해야 한다.</li>
        </ul>
      </li>
      <li>정확하고 사실적인 성격이 강한 task로, 답변인 entity를 조건으로 하여 생성하는 부분이 까다로운 knowledge-intensive task이다.</li>
    </ul>
  </li>
  <li><strong>Fact Verification</strong> (FEVER): 고난이도의 함의 추론과 결합된 검색 문제이다.
    <ul>
      <li>텍스트가 Wikipedia에 따라 맞는 내용인지, 틀렸는지, 또는 판단할 충분한 정보가 없는지를 분류해야 한다.</li>
      <li>모델의 생성 능력이 아닌 분류 능력을 테스트하기에 적절하다.</li>
      <li>Two varients: 3-way classification (supports/refutes/not enough)과 2-way (support/refutes).</li>
    </ul>
  </li>
</ol>

<p><br /></p>

<h1 id="results">Results</h1>

<p>RAG 모델은 여러 task에서 baseline 모델 이상의 성능을 보였다.</p>

<h2 id="open-domain-qa">Open-Domain QA</h2>

<p align="center">
    <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-11-05-rag/table1_2.png?raw=true" style="zoom: 100%;" />
</p>

<ul>
  <li>RAG 모델은 baseline을 크게 능가하는 점수를 기록했다.</li>
  <li>특히 RAG-Token 모델은 여러 문서의 세세한 정보를 통합하는 능력에 의해 우수한 성능을 보였다.</li>
</ul>

<p><br /></p>

<h2 id="abstractive-question-answering">Abstractive Question Answering</h2>

<p align="center">
    <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-11-05-rag/table3.png?raw=true" style="zoom: 100%;" />
</p>

<ul>
  <li>다수의 질문이 gold passage 없이 대답할 수 없었음에도 불구하고 RAG 모델이 SOTA 성능을 달성했다.</li>
  <li>RAG 모델은 BART에 비해 hallucination을 적게 일으켰고 사실적으로 정확하면서도 다양한 텍스트를 생성했다 (Table 3).</li>
</ul>

<p><br /></p>

<h2 id="jeopardy-question-generation">Jeopardy Question Generation</h2>

<p align="center">
    <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-11-05-rag/table4_5.png?raw=true" style="zoom: 100%;" />
</p>
<p>
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-11-05-rag/fig2.png?raw=true" style="zoom: 100%;" />
</p>

<ul>
  <li>두 RAG model 모두 Q-BLEU-1에서 BART를 능가했다 (Table 2).</li>
  <li>Human evaluator는 RAG가 생성한 결과가 42.7%의 경우에서 더 사실적이라고 평가해, SOTA인 generation 모델보다 더 나은 생성 능력을 입증했다 (Table 4).</li>
  <li>RAG-Token 모델이 RAG-Sequence 모델보다 성능이 더 좋게 나타났는데, 여러 문서의 내용을 효과적으로 결합하기 때문인 것으로 생각된다 (Fig 2).</li>
</ul>

<p><br /></p>

<h2 id="fact-verification">Fact Verification</h2>

<ul>
  <li>3-way classification에서 RAG는 특정 도메인에 대한 중간 검색에 대해 지도학습된 SOTA 모델 점수의 4.3% 범위 내의 점수를 기록했다.</li>
  <li>2-way classification에서는 gold evidence를 기반으로 true/false classification을 학습한 SotA 모델과 비교해 2.7% 이내의 성능을 달성했다.</li>
  <li>RAG가 검색한 문서는 FEVER의 gold evidence와 상당 부분 겹쳤다.</li>
</ul>

<p><br /></p>

<h2 id="additional-results">Additional Results</h2>

<ol>
  <li>
    <p><strong>Generation Diversity</strong>: 서로 다른 모델이 생성한 ngram의 비율을 계산하여 output의 다양성을 조사한 결과, RAG 모델이 BART보다 더 다양한 output을 생성했다. RAG-Token보다는 RAG-Sequence의 output이 더 다양했다 (Table 5).</p>
  </li>
  <li>
    <p><strong>Retrieval Ablations</strong>: 학습 중 retriever를 freeze했을 때 원래 방식의 RAG 모델에 비해 성능이 하락했다. Retriever를 BM25로 대체하여 비교했을 때도 학습된 retriever의 성능이 더 높은 것을 볼 수 있었다 (table 6).</p>

    <p align="center">
    <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-11-05-rag/table6.png?raw=true" style="zoom: 100%;" />
</p>
  </li>
  <li>
    <p><strong>Index hot-swapping</strong>: December 2016 Wikipedia dump의 인덱스를 사용하여 non-parametric memory의 이점을 입증했다. RAG 모델은 인덱스가 바뀌었음에도 질문의 70%를 맞게 대답했다. 이로서 non-parametric memory를 단순히 교체하여 knowledge를 업데이트할 수 있음을 알 수 있다.</p>
  </li>
  <li>
    <p><strong>Effect of Retrieving more documents</strong>: 테스트 시 검색될 문서의 수 $k$를 조정한 결과, task에 따라서 특정 개수까지의, 혹은 많은 문서를 검색할수록 성능이 향상되는 것을 볼 수 있다 (fig 3).</p>

    <p align="center">
    <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-11-05-rag/fig3.png?raw=true" style="zoom: 100%;" />
</p>
  </li>
</ol>

<p><br /></p>

    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$$', '$$$'], ['\\[', '\\]'] ],
        processEscapes: true,
      }
    });
    MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="https://alatteaday.github.io/ko/papers/2023/09/15/STraTS/">
        [Paper] Self-Supervised Transformer for Sparse and Irregularly Sampled Multivariate Clinical Time-Series (ACM 2022)
      </a>
    </h1>
    <!--<span class="post-date">15 Sep 2023</span>-->
    <p class="post-date">15 Sep 2023&nbsp;&nbsp;&nbsp;&nbsp;
      
        
          
            <span class="tag" data-tag="bio">
              <a href="https://alatteaday.github.io/ko/tags/?tag=bio">
                #bio
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="ehr">
              <a href="https://alatteaday.github.io/ko/tags/?tag=ehr">
                #ehr
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="transformer">
              <a href="https://alatteaday.github.io/ko/tags/?tag=transformer">
                #transformer
              </a>
            </span>
            
        
      
    </p>
    <!--
    
    -->
    <p>Tipirneni, Sindhu, and Chandan K. Reddy. “Self-supervised transformer for sparse and irregularly sampled multivariate clinical time-series.” <em>ACM Transactions on Knowledge Discovery from Data (TKDD)</em> 16.6 (2022): 1-17.</p>

<p><a href="https://dl.acm.org/doi/full/10.1145/3516367">Paper Link</a></p>

<h2 id="points">Points</h2>

<p><strong>Self-supervised Transformer for Time-Series (STraTS) model</strong></p>

<ul>
  <li>
    <p>Using observation triplets as time-series components: avoids the problems faced by aggregation and imputation methods for sparse and sporadic multivariate time-series</p>
  </li>
  <li>
    <p>Continuous Value Embedding: encodes continuous time and variable values without the need for discretization</p>
  </li>
  <li>
    <p>Transformer-based model: learns contextual triplet embeddings</p>
  </li>
  <li>
    <p>Time series forecasting as a proxy task: leverages unlabeled data to learn better generalized representations</p>
  </li>
</ul>

<h2 id="background">Background</h2>

<p>Problems</p>

<ul>
  <li>Multivariate time-series data are frequently observed in critical care settings and are typically characterized by sparsity (missing information) and irregular time intervals.</li>
  <li>Existing approaches, such as aggregation or imputation of values, suppress the fine-grained information and add undesirable noise/overhead into the model.</li>
  <li>The problem of limited availability of labeled data is easily observed in healthcare applications.</li>
</ul>

<p>The clinical domain portrays a unique set of challenges:</p>

<ul>
  <li>Missingness and Sparsity: Not all the variables are observed for every patient. Also, the time-series matrices are very sparse.</li>
  <li>Irregular time intervals and Sporadicity: Not all clinical variables are measured at regular time intervals. The measurements may occur sporadically in time depending.</li>
  <li>Limited labeled data: expensive and even more limited for specific tasks.</li>
</ul>

<p>Existing methods</p>

<ul>
  <li>Aggregation: could suppress important fine-grained information</li>
  <li>Imputation/Interpolation: not reasonable as not considering the domain knowledge about each variable</li>
</ul>

<h2 id="method">Method</h2>

<p><strong>Self-supervised Transformer for Time-Series (STraTS)</strong></p>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-09-15-strats/1_fig3.png?raw=true" alt="" /></p>

<h3 id="embeddings">Embeddings</h3>

<p><strong>Triplet Emgeddings</strong> = Feature embedding + Value embedding + Time embedding
\(T=\{(t_i, j_i, u_i)\}^n_{i=1}\\
e_i=e_i^f+e_i^v+e_i^t\)
<strong>Continuous Value Embedding (CVE)</strong></p>

<p>For continuous values of feature values and times</p>

<p>A one-to-many Feed-Forward Network
\(FFN(x) = U tanh(Wx+b)\)</p>

<ul>
  <li>
    <p>Feature embeddings $e_i^f$: obtained from a simpole lookup table</p>
  </li>
  <li>
    <p>Value embeddings $e_i^v$ and Time embeddings$e_i^t$: through CVE</p>
  </li>
</ul>

<p><strong>Demographics Embedding</strong></p>

<p>the prediction models performed better when demographics were processed separately.
\(e^𝑑 = 𝑡𝑎𝑛ℎ(W^𝑑_2𝑡𝑎𝑛ℎ(W^𝑑_1d + b^𝑑_1) + b^𝑑_2) ∈ R^d\)
where the hidden layer has a dimension of 2d</p>

<h3 id="self-supervision">Self-Supervision</h3>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-09-15-strats/2_fig2.png?raw=true" alt="" /></p>

<p>Pre-training Tasks: Both masking and forecasting as pretext tasks for providing self-supervision</p>

<p>The forecasitng improved the results on target tasks</p>

<p>The loss is:
\(L_{ss}=\frac{1}{|N'|}\sum_{k=1}^{N'}\sum_{j=1}^{|F|}m_j^k\Big(\tilde{z}_j^k-z_j^k\Big)^2\)</p>

<h3 id="interpretability">Interpretability</h3>

<p>I-STraTS: an interpretable version of STraTS</p>

<ul>
  <li>The output can be expressed using a linear combination of components that are derived from individual features</li>
</ul>

<p>Differences with STraTS</p>

<ul>
  <li>Combine the initial triplet embeddings in Fusion Self-attention module</li>
  <li>Directly use the raw demographics vector as the demographics embedding</li>
</ul>

\[\tilde{y}=sigmoid\Big(\sum_{j=1}^{D}{\bold{w}_0[j]d[j]+\sum_{i=1}^{n}\sum_{j=1}^{d}\alpha_i\bold{w}_o[j+D]\bold{e}_i[j]+b_o}\Big)\]

<h2 id="experiments">Experiments</h2>

<p>Target Task: Prediction of in-hospital mortality</p>

<p>Datasets: 2 EHR datasets; MIMIC-III and PhysioNet Challenge 2012</p>

<ul>
  <li>MIMIC-III: 46,000 patients</li>
  <li>PhysioNet-2012: 11,988 patients</li>
</ul>

<p>Baselines: Gated Recurrent Unit (GRU), Temporal Convolutional Network (TCN), Simply Attend and DIagnose (SaND), GRU with trainable Decays (GRU-D), Interpolation-prediction Network (InterpNet), Set Functions for Time Series (SeFT)</p>

<ul>
  <li>Used 2 dense layers for demographics encoding</li>
  <li>Concatenated it to the time-series representation before the last dense layer</li>
</ul>

<p>Metrics</p>

<ul>
  <li>ROC-AUC: Area under ROC curve</li>
  <li>PR-AUC: Area under precision-recall curve</li>
  <li>min(Re, Pr): the max of ‘min of recall and precision’ across all thresholds</li>
</ul>

<h3 id="prediction-performance">Prediction Performance</h3>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-09-15-strats/3_table4.png?raw=true" style="zoom:80%;" /></p>

<ul>
  <li>Trained each model using 10 different random samplings of 50% labeled data from the train and validation sets</li>
  <li>STraTS uses the entire labeled data and additional unlabeled data if avaliable</li>
  <li>STraTS achieves the best performance</li>
  <li>GRU showed better performance than interpolation-based models (GRU-D, InterpNet) on the MIMIC-III dataset, which was not expected</li>
</ul>

<p><strong>Generalizability test of models</strong></p>

<p>Lower propotions of labeled data can be observed in real-world when there are several right-censord samples.</p>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-09-15-strats/4_fig5.png?raw=true" alt="" /></p>

<ul>
  <li>STraTS has an advantage compared to others in scarce labeled data settings, which can be attributed to self-supervision</li>
</ul>

<h3 id="ablation-study">Ablation Study</h3>

<p>Compared STraTS and I-STraTS with and without self-supervision: ‘ss+’ and ‘ss-‘ indicate each case</p>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-09-15-strats/5_table5.png?raw=true" style="zoom:80%;" /></p>

<ul>
  <li>I-STraTS showed slightly worse performance as constrained its representations</li>
  <li>Adding self-supervision improves performance of both models</li>
  <li>I-STraTS(ss+) outperforms STraTS(ss-): self-supervision can compensate the performance which could get lower by introducing interpretability</li>
</ul>

<h3 id="interpretability-1">Interpretability</h3>

<p>How I-STraTS explains its predictions</p>

<p>A case study: a 85 yrs old female patient from MIMIC-III</p>

<ul>
  <li>expired on the 6th day after ICU admission</li>
  <li>had 380 measurements corresponding to 58 time-series variables</li>
</ul>

<p>The model predicts the probability of her in-hospital mortality as 0.94 using only the data collected the first day</p>

<p><img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-09-15-strats/6_table6.png?raw=true" alt="" /></p>

<ul>
  <li>Average contribution score: the average score along with the range, for multiple observations, or value, for only one observation</li>
  <li>The top 5 variables are the most important factors in predicting she ‘s at high risk of mortality that the model observed</li>
</ul>

<p>&amp;rarr Can be helpful to identify high-risk patients and also understand the contributing factors and make better diagnoses, especially at the early stages of treatment</p>

    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$$', '$$$'], ['\\[', '\\]'] ],
        processEscapes: true,
      }
    });
    MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="https://alatteaday.github.io/ko/study/2023/08/29/demensiapapers/">
        [Study] 알츠하이머 치매의 ATN 바이오마커 간 관계 정리
      </a>
    </h1>
    <!--<span class="post-date">29 Aug 2023</span>-->
    <p class="post-date">29 Aug 2023&nbsp;&nbsp;&nbsp;&nbsp;
      
        
          
            <span class="tag" data-tag="bio">
              <a href="https://alatteaday.github.io/ko/tags/?tag=bio">
                #bio
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="brainImaging">
              <a href="https://alatteaday.github.io/ko/tags/?tag=brainImaging">
                #brainImaging
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="demensia">
              <a href="https://alatteaday.github.io/ko/tags/?tag=demensia">
                #demensia
              </a>
            </span>
            
        
          
            <span class="tag" data-tag="atn">
              <a href="https://alatteaday.github.io/ko/tags/?tag=atn">
                #atn
              </a>
            </span>
            
        
      
    </p>
    <!--
    
      Docker image 및 container와 관련하여 자주 사용되는 명령어를 정리해봅니다.
    
    -->
    <h2 id="ai-전공자의-알츠하이머-치매-관련-brain-imaging-논문-스터디">AI 전공자의 알츠하이머 치매 관련 Brain Imaging 논문 스터디</h2>

<p>Amyloid Beta(A), Tau(T), Neurodegeneration(N)과 관련된 Alzheimer’s Disease(AD) 기전에 대해 이해하기 위하여 다음의 논문들을 읽고 정리한 내용입니다. 기반 지식이 없어 시각 자료와 사전을 찾아가며 읽었습니다. pdf는 찾아본 이미지와 필기한 내용이 담긴 논문 파일입니다.</p>

<p>Ittner, Lars M., and Jürgen Götz. “Amyloid-β and tau—a toxic pas de deux in Alzheimer’s disease.” <em>Nature Reviews Neuroscience</em> 12.2 (2011): 67-72. <a href="https://www.nature.com/articles/nrn2967">link</a> <a href="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-08-29-demensiapapers/nrn2967.pdf">pdf</a></p>

<p>Vogel, Jacob W., et al. “Four distinct trajectories of tau deposition identified in Alzheimer’s disease.” <em>Nature medicine</em> 27.5 (2021): 871-881. <a href="https://www.nature.com/articles/s41591-021-01309-6">link</a> <a href="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-08-29-demensiapapers/s41591-021-01309-6.pdf">pdf</a></p>

<p>Lee, Wha Jin, et al. “Regional Aβ-tau interactions promote onset and acceleration of Alzheimer’s disease tau spreading.” <em>Neuron</em>110.12 (2022): 1932-1943. <a href="https://pubmed.ncbi.nlm.nih.gov/35443153/">link</a> <a href="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2023-08-29-demensiapapers/regional_onset.pdf">pdf</a></p>

<hr />

<p>Amyloid Beta(A)는 뉴런에 의해 생성되는 Amyloid Precursor Protein(APP)이 프로테아제에 의해 4부분으로 나눠질 때 생기는 펩타이드 중 하나로,</p>

<p>뉴런 근처에 존재하여 기능 장애를 야기하는 것으로 알려졌다. A의 침착은 Alzheimer’s Disease(AD) 발병 10-20년 전부터 이뤄진다.</p>

<ul>
  <li>
    <p>A는 dimers, oligomers, fibrils 등에 이어 plaque를 형성한다. A가 어느 형태에서 toxicity를 갖기 시작하는지는 확실하지 않다. 항 아밀로이드 치매 치료제는 이 plaque의 감소와 증식 및 생성 방지를 목적으로 한다.</p>
  </li>
  <li>
    <p>A의 toxicity는 postsynaptic compartment, 즉 dendrite(somatodendritic region)를 주 대상으로 하여 작용하고, 특정 수용체의 속성에 따라 세포막을 통해 간접적으로 뉴런에 영향을 끼칠 수 있다. 대표적인 특정 수용체로 NMDAR이 있다.</p>
  </li>
</ul>

<p>Tau(T)는 신경 세포에서 microtubule과 결합하는 단백질로, 주로 axon에 존재하여 microtubule의 안정화 및 axonal transition을 조절하는 역할을 한다.</p>

<p>정상 상태의 뉴런의 dendrite에도 소량 존재한다.</p>

<p>T는 A에 의해 과인산화되고(hyperphosphorylated Tau), 과인산화된 T는 Neurofibrillary Tangle(NFT)를 형성한다.</p>

<ul>
  <li>T의 과인산화는 microtubule 형성을 방해하여 뉴런의 기능을 방해한다.</li>
  <li>NFT는 Somatodendritic region에서 많이 관찰된다. T의 level이 높아지면 T가 dendrite에서 많이 관찰된다.</li>
</ul>

<p>Dendrite에서 T는 그곳에 위치한 여러 단백질과 상호작용하여 결과적으로 뉴런이 A의 toxicity에 약해지게 만든다.</p>

<ul>
  <li>T가 인산화되면 Tyrosine protein kinasen FYN과 강하게 작용한다. 과인산화된 T가 dendrite에서 증가함에 따라 FYN도 Soma에서 증가한다.</li>
  <li>FYN은 NMDAR을 인산화한다. 인산화된 NMDAR은 Postsynaptic Density Protein 95(PDS95)와 상호작용한다.</li>
  <li>이것의 결과로 NMDAR의 excitotoxicity가 나타난다(흥분독성상태). 수용체의 excitotoxicity로 A의 toxicity에 뉴런이 민감해지게 된다.</li>
</ul>

<p>결과적으로 A와 T는 뉴런을 약화시키는 데에 있어 서로 시너지를 갖는다. A는 T의 과인산화를 촉진하고, 과인산화된 T는 뉴런이 A의 toxicity에 약해지게 만든다.</p>

<p>이 시스템에서 A와 T는 세포의 다른 부분(각각 Complex I, Complex IV)에 악영향을 끼쳐 미토콘드리아 호흡을 방해하고, 결국 Neurodegeneration(N)을 야기한다.</p>

<p>따라서 A의 침착과 T의 전파는 AD의 중요한 요인이다.</p>

<p>T의 전파 양상은 Braak Staging System으로 체계화된 바 있다.</p>

<ul>
  <li>Transentorhinal cortex → medial and basal temporal lobe → neocortical associative regions → unimodal sensory and motor cortex</li>
</ul>

<p>그런데 이 system에 부합하지 않는 전파 양상 또한 관찰되었다. T의 전파 양상을 병의 진행과 뇌 영역의 시공간적 기준으로 분류하여 4가지 subtype으로 정의할 수 있다.</p>

<ul>
  <li>S1 limbic (Braak system), S2 MTL, S3 posterior, S4 Lateral Temporal</li>
</ul>

<p>침착된 A는 T의 전파에 영향을 준다.</p>

<ul>
  <li>A는 heteromodal association cortex에 침착되고, T의 전파는 entorhinal cortex(EC)에서 시작되어 점차 뇌 전반으로 퍼진다. ( ← Braak system; S1 type ? )</li>
  <li>Remote Interation: A와 T가 같은 영역에 있지 않은 상태에서, 먼저 A가 연결된 뉴런을 통해서 EC 영역에 있는 T에 영향을 준다. A의 영향으로 T는 점차 주위 영역으로 확산된다.</li>
  <li>Local Interaction: T가 A와 직접적으로 접촉되어 있는 뉴런에 전파되어 만남으로서 T의 전파가 가속화된다(acceleration). 해당 뇌 영역은 Internal Temporal Gyrus(ITG)이다 (propagation hub).</li>
  <li>T 전파의 acceleration이 진행되면 뇌 전반에서 A와 T의 상호작용이 일어나게 되어 N과 AD의 악화를 막기 어렵다.</li>
</ul>

<p>A와 T의 PET 데이터와 MRI 데이터를 병의 진행에 따라 살펴보면</p>

<ul>
  <li>A의 침착되는 정도는 뇌 전반에 걸쳐 점점 심해질 것이고</li>
  <li>T는 뇌의 특정 부분에서 시작하여 점차 확산되는 양상으로 관찰되고</li>
  <li>T의 슈퍼 전파가 관찰된 이후 MRI 상 전반적인 뇌 위축(N)의 정도가 심하게 나타날 것이다.</li>
</ul>


    
  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="https://alatteaday.github.io/ko/page5">Older</a>
  
  
    
      <a class="pagination-item newer" href="https://alatteaday.github.io/ko/page3">Newer</a>
    
  
</div>

        
      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script src='/public/js/script.js'></script>
  </body>
</html>
