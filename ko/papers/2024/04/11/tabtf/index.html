<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!--site.title site.tagline-->
  <title>
    
      [Paper] Tabtransformer: Tabular data modeling using contextual embeddings (2020) &middot; Coffee Chat
    
  </title>

  
  <link rel="canonical" href="https://alatteaday.github.io/ko/papers/2024/04/11/tabtf/">
  

  <link rel="stylesheet" href="https://alatteaday.github.io/public/css/poole.css">
  <link rel="stylesheet" href="https://alatteaday.github.io/public/css/syntax.css">
  <link rel="stylesheet" href="https://alatteaday.github.io/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://alatteaday.github.io/public/favicon.ico/apple-touch-icon.png">
  <link rel="shortcut icon" href="https://alatteaday.github.io/public/favicon.ico/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="RSS" href="https://alatteaday.github.io/ko/atom.xml">

  
</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>Curation of studies, techs, ideas and a journey as a maching learning engineer</p>
  </div>

  <nav class="sidebar-nav">

    <a class="sidebar-nav-item" href="https://alatteaday.github.io/ko/about">About</a>
    <a class="sidebar-nav-item" href="https://alatteaday.github.io/ko/">Home</a>
    <a class="sidebar-nav-item" href="https://alatteaday.github.io/ko/tags">Tags</a>

    

    
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
          <a class="sidebar-nav-item" 
          href="https://alatteaday.github.io/ko/about/">About</a>
        
        -->
        
      
    
      
    
      
        <!--
        
        -->
        
          <a class="sidebar-nav-item "
          href="https://alatteaday.github.io/ko/category/error/">Dev Tips & Fixes</a>
        
      
    
      
        <!--
        
        -->
        
          <a class="sidebar-nav-item "
          href="https://alatteaday.github.io/ko/category/papers/">Papers</a>
        
      
    
      
        <!--
        
        -->
        
          <a class="sidebar-nav-item "
          href="https://alatteaday.github.io/ko/category/study/">Study</a>
        
      
    
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
      
        <!--
        
        -->
        
      
    
    <!--
    <a class="sidebar-nav-item" href="/ko/archive/v1.1.0.zip">Download</a>
    <a class="sidebar-nav-item" href="">GitHub project</a>
    <span class="sidebar-nav-item">Currently v1.1.0</span> 
    -->
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2024. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <!--site.title site.tagline-->
    <div class="wrap">
      <div class="masthead">
        <div class="container" >
          <h3 class="masthead-title">
            <a href="/ko/" title="Home">Coffee Chat</a>
            <small>Brewing AI Knowledge</small>
          </h3>
          <div class="lang-switcher">
    
    
        
            <a href=" /papers/2024/04/11/tabtf/">eng</a>
        
    

    
    
        kor
    

</div>
        </div>
      </div>

      <div class="container content">
        <div class="post">
  <h1 class="post-title">[Paper] Tabtransformer: Tabular data modeling using contextual embeddings (2020)</h1>
  <p class="post-date">11 Apr 2024&nbsp;&nbsp;&nbsp;&nbsp;
    <!--<span class="post-date">11 Apr 2024</span>-->
    
      
        
          <span class="tag" data-tag="tabular">
            <a href="https://alatteaday.github.io/ko/tags/?tag=tabular">
              #tabular
            </a>
          </span>
        
      
        
          <span class="tag" data-tag="transformer">
            <a href="https://alatteaday.github.io/ko/tags/?tag=transformer">
              #transformer
            </a>
          </span>
        
      
    
  </p>
  <p>Huang, Xin, et al. “Tabtransformer: Tabular data modeling using contextual embeddings.” <em>arXiv preprint arXiv:2012.06678</em> (2020).</p>

<p><a href="https://arxiv.org/abs/2012.06678">Paper Link</a></p>

<p><br /></p>

<h1 id="points">Points</h1>

<ul>
  <li><strong>TabTransformer</strong>: contextual embedding을 활용한 novel tabular data 모델</li>
  <li>Two-phase pre-training 방법을 통해 질 좋은 feature representation을 추출한다.</li>
  <li>Supervised 및 semi-supervised learning에서 모두 SOTA를 달성했다.</li>
  <li>데이터가 누락되거나 일관되지 않은(noisy) 데이터에서도 성능이 안정적이다.</li>
</ul>

<p><br /></p>

<h1 id="background">Background</h1>

<p>기존 tabular data에 대한 모델은 주로 트리 기반 앙상블 방식으로, Gradient boosted decision trees (GBDT)모델이 대표적이다. 그러나 이런 모델은 딥러닝 모델과 비교하여 여러 제한을 가지고 있다:</p>

<ul>
  <li>스트리밍 데이터를 통한 continual learning에 적합하지 않다.</li>
  <li>tabular data의 이미지나 텍스트 등 multi-modality를 end-to-end로 학습하는 데 효과적이지 않다.</li>
  <li>Semi-supervised learning에 적합하지 않다.</li>
</ul>

<p>한편 Multi-layer perceptron (MLP)은 이미지와 텍스트 인코더를 end-to-end로 학습하는 것을 가능하게 하지만, 이것 역시 단점이 있다:</p>

<ul>
  <li>해석하기가(interpretability) 어렵다.</li>
  <li>누락되거나 지저분한 데이터에 대해 취약하다.</li>
  <li>Semi-supervised learning의 상황에서 성능이 제한된다.</li>
  <li>성능이 트리 기반 모델보다 떨어진다.</li>
</ul>

<p><br /></p>

<h1 id="method">Method</h1>

<p align="center">
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2024-04-11-tabtf/archi.png?raw=true" alt="archi" style="zoom: 70%;" />
</p>

<ul>
  <li>Transformer layer는 categorical input만을 입력으로 받는다.</li>
  <li>Continuous input은 Transformer의 출력값과 concatenate된다.</li>
  <li>Pre-training 동안 Transformer layer는 unlabeled data에 대해 두 가지 task를 학습한다.
    <ul>
      <li>Pre-training에서는 continuous input을 배제하고 categorical input만 활용된다.</li>
    </ul>

    <p align="center">
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2024-04-11-tabtf/code1.png?raw=true" alt="code1" style="zoom: 100%;" />
</p>
  </li>
  <li>Pre-trained model은 labeled data를 가지고 MLP head와 같이 target 예측 task에 fine-tuning된다.</li>
  <li>
    <p>Continuous value는 fine-tuning 단계에서 categorical value와 concat되어 사용된다.</p>

    <p align="center">
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2024-04-11-tabtf/code2.png?raw=true" alt="code2" style="zoom: 100%;" />
</p>
  </li>
</ul>

<p><br /></p>

<h2 id="model-architecture">Model Architecture</h2>

<p align="center">
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2024-04-11-tabtf/fig1.png?raw=true" alt="fig1" style="zoom: 60%;" />
</p>

<ul>
  <li>각 입력값 $x\equiv \lbrace x_{cat}, x_{cont}\rbrace$은 해당하는 라벨 $y$를 갖는다: $(x, y)$.</li>
  <li>$x_{cat} \equiv \lbrace x_1, x_2, …, x_m\rbrace$는 입력값 $x_i (i \in {1, …, m})$가 categorical value인 경우의 feature를 가리킨다.</li>
  <li>
    <p>$x_{cat}$은 $E_\phi$로 임베딩된다 (column embedding):</p>

\[E_\phi(x_{cat}) \equiv \lbrace e_{\phi_1}(x_1), ..., e_{\phi_m}(x_m) \rbrace, \ e_{\phi_i}(x_i) \in \mathbb{R}^d\]
  </li>
  <li>
    <p>이 임베딩이 여러 Transformer layer를 통과한다 (contextual embedding):</p>

\[\{h_1, ..., h_m\}=f_\theta(E_\phi(x_{cat})), \ h\in \mathbb{R}^d\]
  </li>
  <li>$x_{cat}$의 contextual embedding은 $x_{cont} \in \mathbb{R}^c $와 concat된다 ($(d\times m+c)$ 차원).</li>
</ul>

<p><br /></p>

<p><strong>Column Embedding</strong></p>

<p align="center">
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2024-04-11-tabtf/colemb.png?raw=true" alt="colemb" style="zoom: 60%;" />
</p>

<ul>
  <li>Categorical feature $x_i$는 각자의 embedding lookup table $e_{\phi_i}(.)$을 갖는다.</li>
  <li>$d_i$개 클래스를 갖는 $i$th feature에 대해, embedding table $e_{\phi_i}(.)$은 $(d_1+1)$개의 embedding으로 구성되는데, 여기서 $d_1+1$번째 embedding은 누락된(masking된) 값을 표현하기 위해서 추가되었다.</li>
  <li>각 embedding $e_{\phi_i}(j)$은 $[c_{\phi_i}, w_{\phi_{ij}}]$로 표현되는데,
    <ul>
      <li>$c_{\phi_i}$는 column $i$에 속하는 클래스를 다른 column 내 클래스와 구분하는 역할을 한다.</li>
      <li>$w_{\phi_{ij}}$는 column $i$에 속하는 한 feature $j$의 클래스를 해당 column 내 다른 클래스들과 구분하는 역할을 한다.</li>
    </ul>
  </li>
  <li>
    <p>*차원 $d$는 코드 상으로 볼 때 hidden size인 $h$와 같은 것으로 보인다.</p>

    <p align="center">
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2024-04-11-tabtf/code3.png?raw=true" alt="code3" style="zoom: 100%;" />
</p>
  </li>
</ul>

<p><br /></p>

<h2 id="pre-training">Pre-training</h2>

<p>Transformer layer는 categorical value $x_{cat}=\lbrace x_1, x_2, …, x_m\rbrace$로 구성된 입력을 가지고 두 가지 task를 수행하며 pre-training된다.</p>

<ol>
  <li><strong>Masked language modeling (MLM)</strong>
    <ul>
      <li>입력값 중 $k\%$의 feature를 랜덤으로 masking한다. 실험에서는 $k$를 30으로 설정했다.</li>
      <li>masking된 feature의 값을 예측하는 multi-class classifier의 cross-entropy loss를 구하여 최소화하는 방향으로 학습한다.</li>
    </ul>
  </li>
  <li><strong>Replaced token detection (RTD)</strong>
    <ul>
      <li>입력값 중 일부의 feature를 랜덤하게 생성된 다른 값으로 바꾼다.</li>
      <li>해당 feature가 바뀌었는지 아닌지를 예측하는 binary classifier의 loss를 최소화하는 방향으로 학습한다.</li>
      <li>각 column은 embedding lookup table을 따로 가지므로, binary classifier 또한 각 column에 대해 따로 구현되었다.</li>
    </ul>
  </li>
</ol>

<p><br /></p>

<h1 id="experiments">Experiments</h1>

<h2 id="settings">Settings</h2>

<p><strong>Data</strong></p>

<ul>
  <li>모든 모들은 15가지 public binary classification 데이터셋에 대해 평가되었다. 데이터셋 출처는 UCI repository, AutoML Challenge, Kaggle.</li>
  <li>모든 데이터셋은 cross-validation을 위해 5개로 나뉘었다.</li>
  <li>Training: Validation: Testing 비율 = 65:15:20 (%)</li>
  <li>Categorical feature는 데이터셋마다 2에서 136가지로 분류된다.</li>
  <li>Semi-supervised 및 supervised 실험 관련
    <ul>
      <li>Semi-supervised: $p$개의 labeled data와 unlabeled data로 학습 데이터를 구성하였다. $p$는 실험 세팅에 따라 $(50, 200, 500)$ 중 하나로 설정되었다.</li>
      <li>Supervised: 모든 데이터가 labeled data.</li>
    </ul>
  </li>
</ul>

<p><strong>Setup</strong></p>

<ul>
  <li>Hidden dimension: 32</li>
  <li>Transformer layer 수: 6</li>
  <li>Attention head 수: 8</li>
  <li>MLP layer 구조: $\lbrace 4\times l, \ 2\times l \rbrace$ ($l$은 입력의 size를 나타낸다).</li>
  <li>매 cross-validation split마다 hyperparamter optimization (HPO)를 20번 수행했다.</li>
  <li>Pre-training은 semi-supervised learning의 경우에만 적용되었다.
    <ul>
      <li>모든 데이터가 라벨이 있는 경우(labeled data)에는 pre-training 유무의 차이를 크게 찾지 못했다.</li>
      <li>Unlabeled data 개수가 많고, labeled data가 적은 학습 상황에서 pre-training의 효과를 더 명확히 발견하였다: 모델이 pre-training을 통해 labeled data에서만으로는 배울 수 없는 representation을 형성할 수 있게 되는 것으로 보인다.</li>
    </ul>
  </li>
</ul>

<p><strong>Baseline model</strong>: MLP 모델</p>

<ul>
  <li>TabTransformer에서 Transformer layer를 제거한 상태의 모델</li>
  <li>Transformer layer의 효과를 평가하기 위해 baseline으로 설정하였다.</li>
</ul>

<p><br /></p>

<h2 id="the-effectiveness-of-the-transformer-layers">The effectiveness of the Transformer Layers</h2>

<ol>
  <li>
    <p><strong>Performance comparison</strong></p>

    <p>Supervised learning의 상황에서 TabTransformer와 MLP를 비교하였다.</p>

    <p align="center">
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2024-04-11-tabtf/table1.png?raw=true" alt="table1" style="zoom: 60%;" />
</p>

    <ul>
      <li>TabTransformer가 14개의 dataset에서 AUC 상 평균적으로 1.0% 정도로 MLP보다 더 좋은 성능을 보였다.</li>
    </ul>
  </li>
  <li>
    <p><strong>t-SNE visualization of contextual embeddings</strong></p>

    <p align="center">
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2024-04-11-tabtf/fig2.png?raw=true" alt="fig2" style="zoom: 100%;" />
</p>

    <ul>
      <li>각 점은 특정 클래스에 속하는 테스트 데이터의 2차원 좌표값을 평균내어 표시하였다.</li>
      <li>마지막 Transformer layer의 t-SNE plot (왼쪽)에서, 의미가 비슷한 클래스끼리 embedding space 상 cluster를 형성하며 가까이 모여있는 것을 볼 수 있다.</li>
      <li>Transformer layer를 통과하기 전 (중간)에도, 성격이 다른 feature의 embedding 간에 구별이 시작되는 것을 볼 수 있다.</li>
      <li>MLP의 embedding (오른쪽)의 경우 어떤 뚜렷한 경향성을 보지 못했다.</li>
    </ul>
  </li>
  <li>
    <p><strong>Prediction performance of linear models using the embeddings from different Transformer layers</strong></p>

    <p>Logistic regression 모델을 사용해 학습된 embedding의 퀄리티를 평가하였다.</p>

    <p align="center">
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2024-04-11-tabtf/fig3.png?raw=true" alt="fig2" style="zoom: 60%;" />
</p>

    <ul>
      <li>각 모델은 embedding과 continuous value를 사용하여 $y$를 예측한다.</li>
      <li>Metrics: Test data를 가지고 평가했을 때, AUC 내 cross-validation 점수</li>
      <li>Normalization: 각 예측 점수는 TabTransformer를 해당 데이터에 학습했을 때 제일 잘 나온 점수에 대해서 normalization되었다.</li>
      <li>Features: embedding은 concatenation 대신 평균한 후 maximum pooling하는 것으로 처리되었다.</li>
      <li>Findings: Transformer layer가 깊어질 수록 embedding의 효과가 커지는 것으로 보인다.</li>
    </ul>
  </li>
</ol>

<p><br /></p>

<h2 id="the-robustness-of-tabtransformer">The robustness of TabTransformer</h2>

<p>데이터가 noisy한 경우와 누락된 경우에 대해 TabTransformer의 성능 안정성을 평가하였다.</p>

<p align="center">
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2024-04-11-tabtf/fig4_5.png?raw=true" alt="fig4_5" style="zoom: 100%;" />
</p>

<ol>
  <li><strong>Noisy data</strong>
    <ul>
      <li>Method: 데이터에 noise를 만들기 위해 특정 값을 해당 columns 내에 존재하는 값 중 랜덤한 값으로 교체한다. 이 데이터로 이미 학습된 모델을 평가한다.</li>
      <li>Findings: 데이터가 noisy할 수록 TabTransformer가 MLP보다 확실히 더 좋은 성능을 보이는 것을 관찰할 수 있다 (fig. 4).</li>
      <li>TabTransformer embedding의 contextual한 성질이 noisy한 데이터에서 큰 효과를 나타내는 것으로 여겨진다.</li>
    </ul>
  </li>
  <li><strong>Data with missing value</strong>
    <ul>
      <li>Method: 일부 값을 일부러 삭제하여 데이터를 조작한 후, 미리 학습된 모델을 평가한다.
        <ul>
          <li>학습된 모델의 embedding 중 특정 column의 모든 클래스의 embedding 평균값으로 누락된 값을 처리했다.</li>
        </ul>
      </li>
      <li>Findings: TabTransformer가 값이 누락된 데이터에서도 MLP보다 더 안정적인 성능을 보였다 (fig. 5).</li>
    </ul>
  </li>
</ol>

<p><br /></p>

<h2 id="supervised-learning">Supervised learning</h2>

<p>Supervised learning의 상황에서 TabTransformer의 성능을 4가지 카테고리의 모델과 비교했다:</p>
<ul>
  <li>Logistic Regression and GBDT</li>
  <li>MLP and sparse MLP</li>
  <li>TabNet model</li>
  <li>Variational Information Bottleneck (VIB) model</li>
</ul>

<p align="center">
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2024-04-11-tabtf/table2.png?raw=true" alt="table2" style="zoom: 70%;" />
</p>

<p>Findings:</p>
<ul>
  <li>TabTransformer가 성능이 제일 좋은 GBDT와 견줄만한 성능을 보였다.</li>
  <li>한편 TabNet과 VIB와 같이 tabular data에 대해 고안된 최신 deep learning 모델보다 확실히 좋은 성능을 보였다.</li>
</ul>

<p><br /></p>

<h2 id="semi-supervised-learning">Semi-supervised learning</h2>

<p>Semi-supervised learning의 상황에서는 TabTransformer의 성능을 다음 모델과 비교했다:</p>
<ul>
  <li>Entropy Regularization (ER)</li>
  <li>Pseudo Labeling (PL) combined with MLP, TabTransformer, and GBDT</li>
  <li>MLP (DAE): An unsupervised pre-training method designed for deep models on tabular data, specifically the swap noise Denoising AutoEncoder</li>
</ul>

<p align="center">
  <img src="https://github.com/alatteaday/alatteaday.github.io/blob/gh-pages/post_images/2024-04-11-tabtf/table3_4.png?raw=true" alt="table3_4" style="zoom: 70%;" />
</p>

<p>Method:</p>
<ul>
  <li>Pre-trained model (TabTransformer-RTD/MLM 및 MLP)의 경우 unlabeled data에 pre-training한 후, labeled data에 fine-tuning했다.</li>
  <li>Semi-supervised learning method (ER 및 PL)의 경우 labeled data와 unlabeled data를 모두 사용하여 학습하였다.</li>
</ul>

<p>Findings:</p>
<ul>
  <li>TabTransformer-RTD/MLM 두 모델이 다른 모델보다 좋은 결과를 나타냈다.</li>
  <li>TabTransformer (ER), TabTransformer (PL) 및 GBDT (PL)은 다른 모델의 평균보다 더 안 좋은 성능을 보였다.</li>
  <li>TabTransformer-RTD가 unlabeled data의 수가 줄어들 수록 더 나은 성능을 보였고, TabTransformer-MLM를 압도했다.
    <ul>
      <li>MLM task인 multi-class classification보다 RTD의 binary classification이 더 쉽기 때문에 학습이 잘 되어 나타난 차이라고 해석된다.</li>
    </ul>
  </li>
  <li>50개의 data point를 가지고 평가했을 때, MLM (ER)과 MLM (PL)이 TabTransformer 모델보다 좋은 성능을 보였다.
    <ul>
      <li>TabTransformer 모델의 경우 unlabeled data에 대해 학습할 때 유용한 embedding을 추출하는 것에 주로 학습될 뿐, classifier 자체의 weight를 update하지 않으므로 나타난 결과라고 여겨진다.</li>
    </ul>
  </li>
  <li>전반적으로 TabTransformer 모델이 unlabeled data에서 유용한 정보를 추출하는 데에 탁월하여, supervised learning 상황에서나, 특히 unlabeled data가 많은 상황에서도 잘 활용될 수 있을 것으로 보인다.</li>
</ul>

</div>


<div class="related">
  <h2 class="related-title">Related posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="/ko/paper/2024/06/14/mriqcsurvey/">
            MRI Quality Assessment 및 Control 관련 네 개 논문 요약&nbsp;
            <small>14 Jun 2024</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/ko/study/2024/05/28/mriqc_report/">
            [MRIQC 4] MRIQC Report와 Image Quality Metrics (IQMs)&nbsp;
            <small>28 May 2024</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/ko/study/dev%20tips%20&%20fixes/2024/05/21/html_flask/">
            [MRIQC 3-1] Flask를 사용해 HTML 파일 열어보기&nbsp;
            <small>21 May 2024</small>
          </a>
        </h3>
      </li>
    
  </ul>
</div>


        
          <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$$', '$$$'], ['\\[', '\\]'] ],
        processEscapes: true,
      }
    });
    MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
</script>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
        
      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script src='/public/js/script.js'></script>
  </body>
</html>
